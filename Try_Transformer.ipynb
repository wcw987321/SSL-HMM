{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Try_Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OABEbFjnKnC"
      },
      "source": [
        "import torch\n",
        "from torch.nn import TransformerEncoderLayer\n",
        "from torch import nn, Tensor\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qHF92sWDYdx"
      },
      "source": [
        "# Data parameters\n",
        "\n",
        "num_hidden_state = 3 # number of hidden states\n",
        "num_obs = 5          # number of possible observations\n",
        "seq_length = 10      # sequence length\n",
        "nsamples = 1000      # number of samples we want to generate\n",
        "\n",
        "# Set model parameters\n",
        "emsize = 200         # embedding dimension/feature dimension\n",
        "d_hid = 2048         # dimension of the feedforward network in TransformerEncoder\n",
        "nhead = 2            # number of heads in multi-head attention\n",
        "ntoken = num_obs     # vocabulary size\n",
        "batch_size = 200     # batch size \n",
        "lr = 1e-3            # learning rate\n",
        "epochs = 200         # number of training epochs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmwRZ_OxjNJt"
      },
      "source": [
        "# Generate HMM parameters\n",
        "def generate_HMM_params(num_hidden_state, num_obs):\n",
        "    # random generate the transition matrix and observation matrix, and compute the stationary distribution\n",
        "    \n",
        "    alpha_state = np.ones(num_hidden_state)\n",
        "    alpha_obs = np.ones(num_obs) / num_obs\n",
        "    trans_mat = np.random.dirichlet(alpha_state, num_hidden_state)\n",
        "    obs_mat = np.random.dirichlet(alpha_obs, num_hidden_state)\n",
        "    tmp = np.ones((num_hidden_state + 1, num_hidden_state))\n",
        "    tmp[:-1] = np.identity(num_hidden_state) - trans_mat.T\n",
        "    tmp_v = np.zeros(num_hidden_state + 1)\n",
        "    tmp_v[-1] = 1\n",
        "    stat_dist = np.linalg.lstsq(tmp, tmp_v, rcond=None)[0]\n",
        "    return trans_mat, obs_mat, stat_dist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWO0xfEKjSuT"
      },
      "source": [
        "# Sample HMM sequences\n",
        "def generate_HMM_sequences(trans_mat, obs_mat, init_dist, length, num_samples = 1):\n",
        "    # generate sample sequences from HMM using the parameters given\n",
        "    \n",
        "    states = np.zeros((num_samples, length))\n",
        "    obs = np.zeros((num_samples, length))\n",
        "    tmp_state = np.argmax(np.random.multinomial(1, init_dist, num_samples), axis = 1)\n",
        "    #print(tmp_state)\n",
        "    for i in range(length):\n",
        "        #print(\"i: \", i)\n",
        "        states[:, i] = tmp_state\n",
        "        for j in range(num_samples):\n",
        "            obs[j, i] = np.random.multinomial(1, obs_mat[tmp_state[j]]).argmax()\n",
        "            tmp_state[j] = np.random.multinomial(1, trans_mat[tmp_state[j]]).argmax()\n",
        "        #print(\"obs[:, i]: \", obs[:, i])\n",
        "    return states, obs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jL_XeUASnt24"
      },
      "source": [
        "# Define Transformer Model\n",
        "class TransformerModel(nn.Module):\n",
        "\n",
        "  def __init__(self, emsize: int, nhead: int, ntoken: int):\n",
        "    super().__init__()\n",
        "    self.emsize = emsize\n",
        "    self.encoder = nn.Embedding(ntoken, emsize)\n",
        "    #self.pos_encoder = PositionalEncoding(emsize, dropout)\n",
        "    self.transformer_encoder = TransformerEncoderLayer(emsize, nhead, d_hid, batch_first=True)\n",
        "    self.decoder = nn.Linear(emsize, ntoken)\n",
        "  \n",
        "  def forward(self, src: Tensor) -> Tensor:\n",
        "    # original input: (batch_size, seq_length)\n",
        "    #print(src.shape)\n",
        "    src = self.encoder(src) * math.sqrt(self.emsize)\n",
        "    # after embedding: (batch_size, seq_length, emsize)\n",
        "    #src = self.pos_encoder(src)\n",
        "    #print(src.shape)\n",
        "    output = self.transformer_encoder(src)\n",
        "    #print(output.shape)\n",
        "    # after encoder: (batch_size, seq_length, emsize)\n",
        "    output = self.decoder(output)\n",
        "    # after decoder: (batch_size, seq_length, ntoken)\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPHOEdVC4v4Z"
      },
      "source": [
        "# Generate HMM parameters and samples used for training\n",
        "seed = 20211121\n",
        "np.random.seed(seed)\n",
        "trans_mat, obs_mat, stat_dist = generate_HMM_params(num_hidden_state, num_obs) # generate parameters for HMM\n",
        "states, obs = generate_HMM_sequences(trans_mat, obs_mat, stat_dist, seq_length, nsamples) # generate sample sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_aUf4Z-tSGu"
      },
      "source": [
        "# Prepare input data\n",
        "dataset = torch.utils.data.TensorDataset(torch.LongTensor(obs))\n",
        "train_dl = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lU7mXAWD9jn"
      },
      "source": [
        "# Set up model instance\n",
        "model = TransformerModel(emsize, nhead, ntoken)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNrQcy5IEXVc"
      },
      "source": [
        "# Set up optimizer and loss\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyO-gCkjGHDT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50963281-c298-4b38-df71-fb52133a45b2"
      },
      "source": [
        "# Training process\n",
        "model.train()\n",
        "for i in range(epochs):\n",
        "  total_loss = 0.\n",
        "  for data in train_dl:\n",
        "    data = data[0]\n",
        "    output = model(data)\n",
        "    loss = criterion(output.transpose(1, 2), data)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss += loss.item()\n",
        "  if i % 10 == 0:\n",
        "    print(total_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6.001508593559265\n",
            "1.2639819383621216\n",
            "0.7904462367296219\n",
            "0.5798290818929672\n",
            "0.4541909098625183\n",
            "0.37019966542720795\n",
            "0.30941810831427574\n",
            "0.26553548127412796\n",
            "0.22933536022901535\n",
            "0.20264381542801857\n",
            "0.1810063160955906\n",
            "0.1622806005179882\n",
            "0.14724822714924812\n",
            "0.13425217755138874\n",
            "0.12368939444422722\n",
            "0.11400996707379818\n",
            "0.10585581883788109\n",
            "0.09840241447091103\n",
            "0.09266022779047489\n",
            "0.08712353557348251\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeZWYTaSHa-p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ecdc094-5cad-4d95-8485-d1f87c1703a5"
      },
      "source": [
        "model.eval()\n",
        "for data in train_dl:\n",
        "  data = data[0]\n",
        "  print(data[:5])\n",
        "  output = model(data) # (batch_size, seq_length, ntoken)\n",
        "  print(output[:5])\n",
        "  #print(output.shape)\n",
        "  #print(data)\n",
        "  #print(data.shape)\n",
        "  #print(output.transpose(1, 2))\n",
        "  #print(output.transpose(1, 2).shape)\n",
        "  loss = criterion(output.transpose(1, 2), data) # CrossEntropyLoss takes input of size (N, C, d) and (N, d) where N: number of data, C: number of classes, d: extra dim, so need to swap the dimension of output from (batch_size, seq_length, ntoken) to (batch_size, ntoken, seq_length)\n",
        "  print(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3, 2, 3, 4, 4, 2, 3, 4, 2, 4],\n",
            "        [4, 2, 2, 4, 4, 2, 4, 2, 4, 4],\n",
            "        [2, 2, 2, 4, 2, 4, 2, 4, 2, 4],\n",
            "        [4, 2, 4, 3, 2, 2, 2, 2, 4, 2],\n",
            "        [4, 4, 2, 2, 2, 4, 4, 0, 3, 2]])\n",
            "tensor([[[-1.6437, -1.7703, -0.9735,  3.2435, -0.1992],\n",
            "         [-1.4774, -0.6050,  5.5317, -1.2283, -1.3134],\n",
            "         [-1.6437, -1.7703, -0.9735,  3.2435, -0.1992],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.4774, -0.6050,  5.5317, -1.2283, -1.3134],\n",
            "         [-1.6437, -1.7703, -0.9735,  3.2435, -0.1992],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.4774, -0.6050,  5.5317, -1.2283, -1.3134],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992]],\n",
            "\n",
            "        [[-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992]],\n",
            "\n",
            "        [[-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992]],\n",
            "\n",
            "        [[-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.4774, -0.6050,  5.5317, -1.2283, -1.3134],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.6437, -1.7703, -0.9735,  3.2435, -0.1992],\n",
            "         [-1.4774, -0.6050,  5.5317, -1.2283, -1.3134],\n",
            "         [-1.4774, -0.6050,  5.5317, -1.2283, -1.3134],\n",
            "         [-1.4774, -0.6050,  5.5317, -1.2283, -1.3134],\n",
            "         [-1.4774, -0.6050,  5.5317, -1.2283, -1.3134],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.4774, -0.6050,  5.5317, -1.2283, -1.3134]],\n",
            "\n",
            "        [[-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.4774, -0.6050,  5.5317, -1.2283, -1.3134],\n",
            "         [-1.4774, -0.6050,  5.5317, -1.2283, -1.3134],\n",
            "         [-1.4774, -0.6050,  5.5317, -1.2283, -1.3134],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [ 3.3616, -0.4185, -0.8430, -0.1375, -0.6309],\n",
            "         [-1.1456, -1.6245, -0.9885,  3.4236, -1.0009],\n",
            "         [-1.4774, -0.6050,  5.5317, -1.2283, -1.3134]]],\n",
            "       grad_fn=<SliceBackward0>)\n",
            "tensor(0.0151, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor([[4, 2, 4, 4, 4, 2, 4, 4, 4, 2],\n",
            "        [3, 2, 0, 3, 0, 2, 4, 4, 2, 4],\n",
            "        [2, 2, 4, 4, 2, 4, 2, 2, 4, 4],\n",
            "        [4, 4, 2, 0, 4, 4, 1, 4, 4, 2],\n",
            "        [4, 2, 4, 4, 2, 2, 4, 2, 4, 2]])\n",
            "tensor([[[-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911]],\n",
            "\n",
            "        [[-1.1456, -1.6245, -0.9885,  3.4236, -1.0010],\n",
            "         [-1.4774, -0.6050,  5.5317, -1.2283, -1.3134],\n",
            "         [ 3.3616, -0.4185, -0.8429, -0.1375, -0.6309],\n",
            "         [-1.1456, -1.6245, -0.9885,  3.4236, -1.0010],\n",
            "         [ 3.3616, -0.4185, -0.8429, -0.1375, -0.6309],\n",
            "         [-1.4774, -0.6050,  5.5317, -1.2283, -1.3134],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.4774, -0.6050,  5.5317, -1.2283, -1.3134],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992]],\n",
            "\n",
            "        [[-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992]],\n",
            "\n",
            "        [[-1.4456, -0.6498, -2.0058, -0.8853,  4.8716],\n",
            "         [-1.4456, -0.6498, -2.0058, -0.8853,  4.8716],\n",
            "         [-1.3662, -0.5937,  5.2883, -0.9100, -1.5322],\n",
            "         [ 3.3616, -0.4185, -0.8430, -0.1375, -0.6309],\n",
            "         [-1.4456, -0.6498, -2.0058, -0.8853,  4.8716],\n",
            "         [-1.4456, -0.6498, -2.0058, -0.8853,  4.8716],\n",
            "         [-0.4056,  2.2957, -0.0791, -1.1282, -1.2427],\n",
            "         [-1.4456, -0.6498, -2.0058, -0.8853,  4.8716],\n",
            "         [-1.4456, -0.6498, -2.0058, -0.8853,  4.8716],\n",
            "         [-1.3662, -0.5937,  5.2883, -0.9100, -1.5322]],\n",
            "\n",
            "        [[-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911]]],\n",
            "       grad_fn=<SliceBackward0>)\n",
            "tensor(0.0160, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor([[4, 4, 2, 2, 4, 4, 2, 2, 2, 4],\n",
            "        [4, 2, 2, 4, 4, 2, 4, 2, 2, 2],\n",
            "        [4, 2, 3, 4, 4, 4, 4, 4, 4, 4],\n",
            "        [2, 0, 4, 2, 0, 3, 3, 4, 4, 4],\n",
            "        [0, 2, 4, 2, 2, 2, 2, 4, 4, 2]])\n",
            "tensor([[[-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992]],\n",
            "\n",
            "        [[-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911]],\n",
            "\n",
            "        [[-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.4774, -0.6050,  5.5317, -1.2283, -1.3134],\n",
            "         [-1.6437, -1.7703, -0.9735,  3.2435, -0.1992],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992]],\n",
            "\n",
            "        [[-1.4774, -0.6050,  5.5317, -1.2283, -1.3134],\n",
            "         [ 3.3616, -0.4185, -0.8429, -0.1375, -0.6309],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.4774, -0.6050,  5.5317, -1.2283, -1.3134],\n",
            "         [ 3.3616, -0.4185, -0.8429, -0.1375, -0.6309],\n",
            "         [-1.1456, -1.6245, -0.9885,  3.4236, -1.0010],\n",
            "         [-1.1456, -1.6245, -0.9885,  3.4236, -1.0010],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992]],\n",
            "\n",
            "        [[ 3.3616, -0.4185, -0.8430, -0.1376, -0.6309],\n",
            "         [-1.3662, -0.5937,  5.2882, -0.9100, -1.5322],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.3662, -0.5937,  5.2882, -0.9100, -1.5322],\n",
            "         [-1.3662, -0.5937,  5.2882, -0.9100, -1.5322],\n",
            "         [-1.3662, -0.5937,  5.2882, -0.9100, -1.5322],\n",
            "         [-1.3662, -0.5937,  5.2882, -0.9100, -1.5322],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.3662, -0.5937,  5.2882, -0.9100, -1.5322]]],\n",
            "       grad_fn=<SliceBackward0>)\n",
            "tensor(0.0134, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor([[2, 2, 2, 4, 2, 2, 2, 2, 4, 2],\n",
            "        [4, 2, 2, 2, 2, 4, 2, 3, 2, 4],\n",
            "        [4, 2, 4, 2, 2, 4, 2, 4, 4, 2],\n",
            "        [4, 2, 2, 2, 3, 4, 0, 0, 4, 4],\n",
            "        [2, 2, 2, 4, 4, 4, 2, 0, 4, 4]])\n",
            "tensor([[[-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911]],\n",
            "\n",
            "        [[-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.4774, -0.6050,  5.5317, -1.2283, -1.3134],\n",
            "         [-1.4774, -0.6050,  5.5317, -1.2283, -1.3134],\n",
            "         [-1.4774, -0.6050,  5.5317, -1.2283, -1.3134],\n",
            "         [-1.4774, -0.6050,  5.5317, -1.2283, -1.3134],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.4774, -0.6050,  5.5317, -1.2283, -1.3134],\n",
            "         [-1.6437, -1.7703, -0.9735,  3.2435, -0.1992],\n",
            "         [-1.4774, -0.6050,  5.5317, -1.2283, -1.3134],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992]],\n",
            "\n",
            "        [[-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911]],\n",
            "\n",
            "        [[-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.4774, -0.6050,  5.5317, -1.2283, -1.3134],\n",
            "         [-1.4774, -0.6050,  5.5317, -1.2283, -1.3134],\n",
            "         [-1.4774, -0.6050,  5.5317, -1.2283, -1.3134],\n",
            "         [-1.1456, -1.6245, -0.9885,  3.4236, -1.0010],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [ 3.3616, -0.4185, -0.8429, -0.1375, -0.6309],\n",
            "         [ 3.3616, -0.4185, -0.8429, -0.1375, -0.6309],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992]],\n",
            "\n",
            "        [[-1.3662, -0.5937,  5.2882, -0.9100, -1.5322],\n",
            "         [-1.3662, -0.5937,  5.2882, -0.9100, -1.5322],\n",
            "         [-1.3662, -0.5937,  5.2882, -0.9100, -1.5322],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.3662, -0.5937,  5.2882, -0.9100, -1.5322],\n",
            "         [ 3.3616, -0.4185, -0.8430, -0.1375, -0.6309],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992]]],\n",
            "       grad_fn=<SliceBackward0>)\n",
            "tensor(0.0160, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor([[4, 2, 0, 4, 4, 4, 4, 4, 2, 2],\n",
            "        [4, 2, 4, 2, 2, 4, 2, 2, 2, 4],\n",
            "        [2, 2, 4, 2, 2, 4, 4, 4, 4, 2],\n",
            "        [4, 2, 3, 2, 4, 2, 2, 4, 2, 4],\n",
            "        [2, 2, 2, 2, 4, 4, 4, 2, 2, 2]])\n",
            "tensor([[[-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.3662, -0.5938,  5.2883, -0.9100, -1.5322],\n",
            "         [ 3.3616, -0.4185, -0.8430, -0.1375, -0.6309],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.3662, -0.5938,  5.2883, -0.9100, -1.5322],\n",
            "         [-1.3662, -0.5938,  5.2883, -0.9100, -1.5322]],\n",
            "\n",
            "        [[-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992]],\n",
            "\n",
            "        [[-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911]],\n",
            "\n",
            "        [[-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.4774, -0.6050,  5.5317, -1.2283, -1.3134],\n",
            "         [-1.6437, -1.7703, -0.9735,  3.2435, -0.1992],\n",
            "         [-1.4774, -0.6050,  5.5317, -1.2283, -1.3134],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.4774, -0.6050,  5.5317, -1.2283, -1.3134],\n",
            "         [-1.4774, -0.6050,  5.5317, -1.2283, -1.3134],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.4774, -0.6050,  5.5317, -1.2283, -1.3134],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992]],\n",
            "\n",
            "        [[-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.7631, -1.6035, -1.8294, -0.7417,  5.0992],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911],\n",
            "         [-1.3730, -0.7473,  5.5607, -0.8609, -1.5911]]],\n",
            "       grad_fn=<SliceBackward0>)\n",
            "tensor(0.0133, grad_fn=<NllLoss2DBackward0>)\n"
          ]
        }
      ]
    }
  ]
}