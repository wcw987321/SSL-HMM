{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Try_Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OABEbFjnKnC"
      },
      "source": [
        "import torch\n",
        "from torch.nn import TransformerEncoderLayer\n",
        "from torch import nn, Tensor\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import math"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qHF92sWDYdx"
      },
      "source": [
        "# Data parameters\n",
        "\n",
        "num_hidden_state = 3 # number of hidden states\n",
        "num_obs = 5          # number of possible observations\n",
        "seq_length = 10      # sequence length\n",
        "nsamples = 1000      # number of samples we want to generate\n",
        "\n",
        "# Set model parameters\n",
        "emsize = 200         # embedding dimension/feature dimension\n",
        "d_hid = 2048         # dimension of the feedforward network in TransformerEncoder\n",
        "nhead = 2            # number of heads in multi-head attention\n",
        "ntoken = num_obs + 1 # vocabulary size\n",
        "batch_size = 200     # batch size \n",
        "lr = 1e-3            # learning rate\n",
        "epochs = 200         # number of training epochs"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmwRZ_OxjNJt"
      },
      "source": [
        "# Generate HMM parameters\n",
        "def generate_HMM_params(num_hidden_state, num_obs):\n",
        "    # random generate the transition matrix and observation matrix, and compute the stationary distribution\n",
        "    \n",
        "    alpha_state = np.ones(num_hidden_state)\n",
        "    alpha_obs = np.ones(num_obs) / num_obs\n",
        "    trans_mat = np.random.dirichlet(alpha_state, num_hidden_state)\n",
        "    obs_mat = np.random.dirichlet(alpha_obs, num_hidden_state)\n",
        "    tmp = np.ones((num_hidden_state + 1, num_hidden_state))\n",
        "    tmp[:-1] = np.identity(num_hidden_state) - trans_mat.T\n",
        "    tmp_v = np.zeros(num_hidden_state + 1)\n",
        "    tmp_v[-1] = 1\n",
        "    stat_dist = np.linalg.lstsq(tmp, tmp_v, rcond=None)[0]\n",
        "    return trans_mat, obs_mat, stat_dist"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWO0xfEKjSuT"
      },
      "source": [
        "# Sample HMM sequences\n",
        "def generate_HMM_sequences(trans_mat, obs_mat, init_dist, length, num_samples = 1):\n",
        "    # generate sample sequences from HMM using the parameters given\n",
        "    \n",
        "    states = np.zeros((num_samples, length))\n",
        "    obs = np.zeros((num_samples, length))\n",
        "    tmp_state = np.argmax(np.random.multinomial(1, init_dist, num_samples), axis = 1)\n",
        "    #print(tmp_state)\n",
        "    for i in range(length):\n",
        "        #print(\"i: \", i)\n",
        "        states[:, i] = tmp_state\n",
        "        for j in range(num_samples):\n",
        "            obs[j, i] = np.random.multinomial(1, obs_mat[tmp_state[j]]).argmax()\n",
        "            tmp_state[j] = np.random.multinomial(1, trans_mat[tmp_state[j]]).argmax()\n",
        "        #print(\"obs[:, i]: \", obs[:, i])\n",
        "    return states, obs"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RDCKvMtj_8c"
      },
      "source": [
        "# Add [mask] tokens to input, one per sequence\n",
        "def add_mask_to_sequences(seqs, pos):\n",
        "  masked_seqs = np.copy(seqs)\n",
        "  for i in range(nsamples):\n",
        "    masked_seqs[i, pos[i]] = num_obs\n",
        "  return masked_seqs"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jL_XeUASnt24"
      },
      "source": [
        "# Define Transformer Model\n",
        "class TransformerModel(nn.Module):\n",
        "\n",
        "  def __init__(self, emsize: int, nhead: int, ntoken: int):\n",
        "    super().__init__()\n",
        "    self.emsize = emsize\n",
        "    self.encoder = nn.Embedding(ntoken, emsize)\n",
        "    #self.pos_encoder = PositionalEncoding(emsize, dropout)\n",
        "    self.transformer_encoder = TransformerEncoderLayer(emsize, nhead, d_hid, batch_first=True)\n",
        "    self.decoder = nn.Linear(emsize, ntoken)\n",
        "  \n",
        "  def forward(self, src: Tensor) -> Tensor:\n",
        "    # original input: (batch_size, seq_length)\n",
        "    #print(src.shape)\n",
        "    src = self.encoder(src) * math.sqrt(self.emsize)\n",
        "    # after embedding: (batch_size, seq_length, emsize)\n",
        "    #src = self.pos_encoder(src)\n",
        "    #print(src.shape)\n",
        "    output = self.transformer_encoder(src)\n",
        "    #print(output.shape)\n",
        "    # after encoder: (batch_size, seq_length, emsize)\n",
        "    output = self.decoder(output)\n",
        "    # after decoder: (batch_size, seq_length, ntoken)\n",
        "    return output"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPHOEdVC4v4Z"
      },
      "source": [
        "# Generate HMM parameters and samples used for training\n",
        "seed = 20211121\n",
        "np.random.seed(seed)\n",
        "trans_mat, obs_mat, stat_dist = generate_HMM_params(num_hidden_state, num_obs) # generate parameters for HMM\n",
        "states, obs = generate_HMM_sequences(trans_mat, obs_mat, stat_dist, seq_length, nsamples) # generate training sequences\n",
        "pos = np.random.randint(seq_length, size = nsamples) # positions for masks, nsamples-dimensional array\n",
        "masked_obs = add_mask_to_sequences(obs, pos)\n",
        "val_states, val_obs = generate_HMM_sequences(trans_mat, obs_mat, stat_dist, seq_length, nsamples) # generate validation sequences\n",
        "val_pos = np.random.randint(seq_length, size = nsamples)\n",
        "val_masked_obs = add_mask_to_sequences(val_obs, val_pos)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_aUf4Z-tSGu"
      },
      "source": [
        "# Prepare input data and validation data\n",
        "dataset = torch.utils.data.TensorDataset(torch.LongTensor(masked_obs), torch.LongTensor(obs))\n",
        "val_dataset = torch.utils.data.TensorDataset(torch.LongTensor(val_masked_obs), torch.LongTensor(val_obs))\n",
        "train_dl = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "val_dl = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lU7mXAWD9jn"
      },
      "source": [
        "# Set up model instance\n",
        "model = TransformerModel(emsize, nhead, ntoken)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNrQcy5IEXVc"
      },
      "source": [
        "# Set up optimizer and loss\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyO-gCkjGHDT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06375237-be09-49c7-cc35-a06e825049cf"
      },
      "source": [
        "# Training process\n",
        "model.train()\n",
        "for i in range(epochs):\n",
        "  total_loss = 0.\n",
        "  for data, target in train_dl:\n",
        "    #data = data[0]\n",
        "    output = model(data)\n",
        "    loss = criterion(output.transpose(1, 2), target)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss += loss.item()\n",
        "  if i % 10 == 0:\n",
        "    print(\"epoch \" + str(i))\n",
        "    print(\"training loss: \" + str(total_loss))\n",
        "    model.eval()\n",
        "    total_val_loss = 0.\n",
        "    total_val_train_loss = 0.\n",
        "    for val_data, val_target in val_dl:\n",
        "      #val_data = val_data[0]\n",
        "      val_output = model(val_data)\n",
        "      val_loss = criterion(val_output.transpose(1, 2), val_target)\n",
        "      total_val_loss += val_loss.item()\n",
        "    for val_train_data, val_train_target in train_dl:\n",
        "      val_train_output = model(val_train_data)\n",
        "      val_train_loss = criterion(val_train_output.transpose(1, 2), val_train_target)\n",
        "      total_val_train_loss += val_train_loss.item()\n",
        "    print(\"val loss: \" + str(total_val_loss))\n",
        "    print(\"val train loss: \" + str(total_val_train_loss))\n",
        "    model.train()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0\n",
            "training loss: 9.206130743026733\n",
            "val loss: 7.8179692029953\n",
            "val train loss: 7.8618611097335815\n",
            "epoch 10\n",
            "training loss: 2.173106074333191\n",
            "val loss: 1.9837653934955597\n",
            "val train loss: 2.0522585809230804\n",
            "epoch 20\n",
            "training loss: 1.5233761370182037\n",
            "val loss: 1.4067131876945496\n",
            "val train loss: 1.4668624997138977\n",
            "epoch 30\n",
            "training loss: 1.256676271557808\n",
            "val loss: 1.166317641735077\n",
            "val train loss: 1.218151479959488\n",
            "epoch 40\n",
            "training loss: 1.1047970205545425\n",
            "val loss: 1.0251283794641495\n",
            "val train loss: 1.0701913386583328\n",
            "epoch 50\n",
            "training loss: 0.9998591542243958\n",
            "val loss: 0.9308434128761292\n",
            "val train loss: 0.9706205725669861\n",
            "epoch 60\n",
            "training loss: 0.9237363189458847\n",
            "val loss: 0.8635053485631943\n",
            "val train loss: 0.8992139846086502\n",
            "epoch 70\n",
            "training loss: 0.8710628300905228\n",
            "val loss: 0.8133158981800079\n",
            "val train loss: 0.8458731919527054\n",
            "epoch 80\n",
            "training loss: 0.8243516683578491\n",
            "val loss: 0.7747923731803894\n",
            "val train loss: 0.8048716634511948\n",
            "epoch 90\n",
            "training loss: 0.794848769903183\n",
            "val loss: 0.7444488406181335\n",
            "val train loss: 0.7725466042757034\n",
            "epoch 100\n",
            "training loss: 0.7652984708547592\n",
            "val loss: 0.7201262563467026\n",
            "val train loss: 0.7466214746236801\n",
            "epoch 110\n",
            "training loss: 0.7416202872991562\n",
            "val loss: 0.7003606408834457\n",
            "val train loss: 0.7255288809537888\n",
            "epoch 120\n",
            "training loss: 0.7250333875417709\n",
            "val loss: 0.6840289533138275\n",
            "val train loss: 0.7080890387296677\n",
            "epoch 130\n",
            "training loss: 0.7087896317243576\n",
            "val loss: 0.6703507751226425\n",
            "val train loss: 0.6934575736522675\n",
            "epoch 140\n",
            "training loss: 0.6962695419788361\n",
            "val loss: 0.6587981879711151\n",
            "val train loss: 0.6810815185308456\n",
            "epoch 150\n",
            "training loss: 0.6858628690242767\n",
            "val loss: 0.6489309221506119\n",
            "val train loss: 0.6704885587096214\n",
            "epoch 160\n",
            "training loss: 0.6759762614965439\n",
            "val loss: 0.6404145136475563\n",
            "val train loss: 0.6613331213593483\n",
            "epoch 170\n",
            "training loss: 0.6664242520928383\n",
            "val loss: 0.6330276876688004\n",
            "val train loss: 0.6533693075180054\n",
            "epoch 180\n",
            "training loss: 0.6610286757349968\n",
            "val loss: 0.626541905105114\n",
            "val train loss: 0.646369181573391\n",
            "epoch 190\n",
            "training loss: 0.6523072794079781\n",
            "val loss: 0.6208557486534119\n",
            "val train loss: 0.6402090415358543\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeZWYTaSHa-p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a27c1e4-e055-4a2c-f7a8-8446eb5c20be"
      },
      "source": [
        "train_err = 0\n",
        "train_mask_err = 0\n",
        "val_err = 0\n",
        "val_mask_err = 0\n",
        "model.eval()\n",
        "for data, target in train_dl:\n",
        "  #data = data[0]\n",
        "  print(data[:5])\n",
        "  output = model(data) # (batch_size, seq_length, ntoken)\n",
        "  train_err += torch.sum(torch.argmax(output, dim=2) != target)\n",
        "  train_mask_err += torch.sum((data != target) * (torch.argmax(output, dim=2) != target))\n",
        "  print(output[:5])\n",
        "  print(torch.argmax(output, dim=2)[:5])\n",
        "  print(target[:5])\n",
        "  #print(output.shape)\n",
        "  #print(data)\n",
        "  #print(data.shape)\n",
        "  #print(output.transpose(1, 2))\n",
        "  #print(output.transpose(1, 2).shape)\n",
        "  #loss = criterion(output.transpose(1, 2), target) # CrossEntropyLoss takes input of size (N, C, d) and (N, d) where N: number of data, C: number of classes, d: extra dim, so need to swap the dimension of output from (batch_size, seq_length, ntoken) to (batch_size, ntoken, seq_length)\n",
        "  #print(loss)\n",
        "  break\n",
        "for val_data, val_target in val_dl:\n",
        "  #val_data = val_data[0]\n",
        "  print(val_data[:5])\n",
        "  val_output = model(val_data)\n",
        "  val_err += torch.sum(torch.argmax(val_output, dim=2) != val_target)\n",
        "  val_mask_err += torch.sum((val_data != val_target) * (torch.argmax(val_output, dim=2) != val_target))\n",
        "  print(val_output[:5])\n",
        "  print(torch.argmax(val_output, dim=2)[:5])\n",
        "  print(val_target[:5])\n",
        "  #val_loss = criterion(val_output.transpose(1, 2), val_target)\n",
        "  #print(val_loss)\n",
        "  break\n",
        "print(train_err)\n",
        "print(train_mask_err)\n",
        "print(val_err)\n",
        "print(val_mask_err)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3, 2, 3, 4, 4, 5, 3, 4, 2, 4],\n",
            "        [4, 2, 2, 4, 4, 2, 4, 2, 4, 5],\n",
            "        [2, 2, 2, 4, 2, 4, 2, 4, 2, 5],\n",
            "        [4, 2, 5, 3, 2, 2, 2, 2, 4, 2],\n",
            "        [5, 4, 2, 2, 2, 4, 4, 0, 3, 2]])\n",
            "tensor([[[-0.3101, -0.5406, -0.4460,  3.9307, -0.4764, -0.9454],\n",
            "         [-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564],\n",
            "         [-0.3101, -0.5406, -0.4460,  3.9307, -0.4764, -0.9454],\n",
            "         [-1.4830, -1.7898, -0.7918, -1.0090,  5.2828, -1.8716],\n",
            "         [-1.4830, -1.7898, -0.7918, -1.0090,  5.2828, -1.8716],\n",
            "         [-0.8322, -0.7625,  2.2040, -0.1447,  1.9869, -1.5643],\n",
            "         [-0.3101, -0.5406, -0.4460,  3.9307, -0.4764, -0.9454],\n",
            "         [-1.4830, -1.7898, -0.7918, -1.0090,  5.2828, -1.8716],\n",
            "         [-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564],\n",
            "         [-1.4830, -1.7898, -0.7918, -1.0090,  5.2828, -1.8716]],\n",
            "\n",
            "        [[-1.4830, -1.7898, -0.7918, -1.0090,  5.2828, -1.8716],\n",
            "         [-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564],\n",
            "         [-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564],\n",
            "         [-1.4830, -1.7898, -0.7918, -1.0090,  5.2828, -1.8716],\n",
            "         [-1.4830, -1.7898, -0.7918, -1.0090,  5.2828, -1.8716],\n",
            "         [-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564],\n",
            "         [-1.4830, -1.7898, -0.7918, -1.0090,  5.2828, -1.8716],\n",
            "         [-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564],\n",
            "         [-1.4830, -1.7898, -0.7918, -1.0090,  5.2828, -1.8716],\n",
            "         [-0.8322, -0.7625,  2.2040, -0.1447,  1.9869, -1.5643]],\n",
            "\n",
            "        [[-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564],\n",
            "         [-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564],\n",
            "         [-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564],\n",
            "         [-1.4830, -1.7898, -0.7918, -1.0090,  5.2828, -1.8716],\n",
            "         [-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564],\n",
            "         [-1.4830, -1.7898, -0.7918, -1.0090,  5.2828, -1.8716],\n",
            "         [-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564],\n",
            "         [-1.4830, -1.7898, -0.7918, -1.0090,  5.2828, -1.8716],\n",
            "         [-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564],\n",
            "         [-0.8322, -0.7625,  2.2040, -0.1447,  1.9869, -1.5643]],\n",
            "\n",
            "        [[-1.4830, -1.7898, -0.7918, -1.0090,  5.2828, -1.8716],\n",
            "         [-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564],\n",
            "         [-0.8322, -0.7625,  2.2040, -0.1447,  1.9869, -1.5643],\n",
            "         [-0.3101, -0.5406, -0.4460,  3.9307, -0.4764, -0.9454],\n",
            "         [-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564],\n",
            "         [-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564],\n",
            "         [-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564],\n",
            "         [-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564],\n",
            "         [-1.4830, -1.7898, -0.7918, -1.0090,  5.2828, -1.8716],\n",
            "         [-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564]],\n",
            "\n",
            "        [[-0.2998, -0.5999,  1.8036, -0.3730,  1.4930, -1.3590],\n",
            "         [-1.4830, -1.7898, -0.7918, -1.0090,  5.2828, -1.8716],\n",
            "         [-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564],\n",
            "         [-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564],\n",
            "         [-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564],\n",
            "         [-1.4830, -1.7898, -0.7918, -1.0090,  5.2828, -1.8716],\n",
            "         [-1.4830, -1.7898, -0.7918, -1.0090,  5.2828, -1.8716],\n",
            "         [ 2.8452, -0.5867, -1.5407, -0.0177, -0.8717, -1.1588],\n",
            "         [-0.3101, -0.5406, -0.4460,  3.9307, -0.4764, -0.9454],\n",
            "         [-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564]]],\n",
            "       grad_fn=<SliceBackward0>)\n",
            "tensor([[3, 2, 3, 4, 4, 2, 3, 4, 2, 4],\n",
            "        [4, 2, 2, 4, 4, 2, 4, 2, 4, 2],\n",
            "        [2, 2, 2, 4, 2, 4, 2, 4, 2, 2],\n",
            "        [4, 2, 2, 3, 2, 2, 2, 2, 4, 2],\n",
            "        [2, 4, 2, 2, 2, 4, 4, 0, 3, 2]])\n",
            "tensor([[3, 2, 3, 4, 4, 2, 3, 4, 2, 4],\n",
            "        [4, 2, 2, 4, 4, 2, 4, 2, 4, 4],\n",
            "        [2, 2, 2, 4, 2, 4, 2, 4, 2, 4],\n",
            "        [4, 2, 4, 3, 2, 2, 2, 2, 4, 2],\n",
            "        [4, 4, 2, 2, 2, 4, 4, 0, 3, 2]])\n",
            "tensor([[2, 4, 2, 4, 4, 4, 2, 5, 2, 0],\n",
            "        [4, 2, 2, 4, 2, 4, 5, 2, 2, 2],\n",
            "        [4, 2, 4, 2, 2, 4, 2, 2, 5, 4],\n",
            "        [2, 5, 4, 2, 2, 2, 3, 4, 2, 4],\n",
            "        [4, 4, 5, 2, 0, 4, 3, 3, 3, 2]])\n",
            "tensor([[[-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564],\n",
            "         [-1.4830, -1.7898, -0.7918, -1.0090,  5.2828, -1.8716],\n",
            "         [-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564],\n",
            "         [-1.4830, -1.7898, -0.7918, -1.0090,  5.2828, -1.8716],\n",
            "         [-1.4830, -1.7898, -0.7918, -1.0090,  5.2828, -1.8716],\n",
            "         [-1.4830, -1.7898, -0.7918, -1.0090,  5.2828, -1.8716],\n",
            "         [-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564],\n",
            "         [-0.2998, -0.5999,  1.8036, -0.3730,  1.4930, -1.3590],\n",
            "         [-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564],\n",
            "         [ 2.8452, -0.5867, -1.5407, -0.0177, -0.8717, -1.1588]],\n",
            "\n",
            "        [[-1.4830, -1.7898, -0.7918, -1.0090,  5.2828, -1.8716],\n",
            "         [-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564],\n",
            "         [-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564],\n",
            "         [-1.4830, -1.7898, -0.7918, -1.0090,  5.2828, -1.8716],\n",
            "         [-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564],\n",
            "         [-1.4830, -1.7898, -0.7918, -1.0090,  5.2828, -1.8716],\n",
            "         [-0.8322, -0.7625,  2.2040, -0.1447,  1.9869, -1.5643],\n",
            "         [-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564],\n",
            "         [-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564],\n",
            "         [-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564]],\n",
            "\n",
            "        [[-1.4830, -1.7898, -0.7918, -1.0090,  5.2828, -1.8716],\n",
            "         [-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564],\n",
            "         [-1.4830, -1.7898, -0.7918, -1.0090,  5.2828, -1.8716],\n",
            "         [-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564],\n",
            "         [-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564],\n",
            "         [-1.4830, -1.7898, -0.7918, -1.0090,  5.2828, -1.8716],\n",
            "         [-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564],\n",
            "         [-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564],\n",
            "         [-0.8322, -0.7625,  2.2040, -0.1447,  1.9869, -1.5643],\n",
            "         [-1.4830, -1.7898, -0.7918, -1.0090,  5.2828, -1.8716]],\n",
            "\n",
            "        [[-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564],\n",
            "         [-0.8322, -0.7625,  2.2040, -0.1447,  1.9869, -1.5643],\n",
            "         [-1.4830, -1.7898, -0.7918, -1.0090,  5.2828, -1.8716],\n",
            "         [-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564],\n",
            "         [-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564],\n",
            "         [-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564],\n",
            "         [-0.3101, -0.5406, -0.4460,  3.9307, -0.4764, -0.9454],\n",
            "         [-1.4830, -1.7898, -0.7918, -1.0090,  5.2828, -1.8716],\n",
            "         [-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564],\n",
            "         [-1.4830, -1.7898, -0.7918, -1.0090,  5.2828, -1.8716]],\n",
            "\n",
            "        [[-1.4830, -1.7898, -0.7918, -1.0090,  5.2828, -1.8716],\n",
            "         [-1.4830, -1.7898, -0.7918, -1.0090,  5.2828, -1.8716],\n",
            "         [-0.2998, -0.5999,  1.8036, -0.3730,  1.4930, -1.3590],\n",
            "         [-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564],\n",
            "         [ 2.8452, -0.5867, -1.5407, -0.0177, -0.8717, -1.1588],\n",
            "         [-1.4830, -1.7898, -0.7918, -1.0090,  5.2828, -1.8716],\n",
            "         [-0.3101, -0.5406, -0.4460,  3.9307, -0.4764, -0.9454],\n",
            "         [-0.3101, -0.5406, -0.4460,  3.9307, -0.4764, -0.9454],\n",
            "         [-0.3101, -0.5406, -0.4460,  3.9307, -0.4764, -0.9454],\n",
            "         [-1.0763, -1.1138,  6.0035, -0.7718, -0.0813, -1.0564]]],\n",
            "       grad_fn=<SliceBackward0>)\n",
            "tensor([[2, 4, 2, 4, 4, 4, 2, 2, 2, 0],\n",
            "        [4, 2, 2, 4, 2, 4, 2, 2, 2, 2],\n",
            "        [4, 2, 4, 2, 2, 4, 2, 2, 2, 4],\n",
            "        [2, 2, 4, 2, 2, 2, 3, 4, 2, 4],\n",
            "        [4, 4, 2, 2, 0, 4, 3, 3, 3, 2]])\n",
            "tensor([[2, 4, 2, 4, 4, 4, 2, 4, 2, 0],\n",
            "        [4, 2, 2, 4, 2, 4, 2, 2, 2, 2],\n",
            "        [4, 2, 4, 2, 2, 4, 2, 2, 2, 4],\n",
            "        [2, 2, 4, 2, 2, 2, 3, 4, 2, 4],\n",
            "        [4, 4, 2, 2, 0, 4, 3, 3, 3, 2]])\n",
            "tensor(81)\n",
            "tensor(81)\n",
            "tensor(108)\n",
            "tensor(108)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wi2kJ3ZamPSJ"
      },
      "source": [
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    }
  ]
}