{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameter setting\n",
    "num_hidden_state = 3\n",
    "num_obs = 5\n",
    "length = 10\n",
    "num_samples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define some useful functions\n",
    "def generate_HMM_params(num_hidden_state, num_obs):\n",
    "    # random generate the transition matrix and observation matrix, and compute the stationary distribution\n",
    "    \n",
    "    alpha_state = np.ones(num_hidden_state)\n",
    "    alpha_obs = np.ones(num_obs) / num_obs\n",
    "    trans_mat = np.random.dirichlet(alpha_state, num_hidden_state)\n",
    "    obs_mat = np.random.dirichlet(alpha_obs, num_hidden_state)\n",
    "    tmp = np.ones((num_hidden_state + 1, num_hidden_state))\n",
    "    tmp[:-1] = np.identity(num_hidden_state) - trans_mat.T\n",
    "    tmp_v = np.zeros(num_hidden_state + 1)\n",
    "    tmp_v[-1] = 1\n",
    "    stat_dist = np.linalg.lstsq(tmp, tmp_v, rcond=None)[0]\n",
    "    return trans_mat, obs_mat, stat_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_HMM_sequences(trans_mat, obs_mat, init_dist, length, num_samples = 1):\n",
    "    # generate sample sequences from HMM\n",
    "    \n",
    "    states = np.zeros((num_samples, length))\n",
    "    obs = np.zeros((num_samples, length))\n",
    "    tmp_state = np.argmax(np.random.multinomial(1, init_dist, num_samples), axis = 1)\n",
    "    #print(tmp_state)\n",
    "    for i in range(length):\n",
    "        #print(\"i: \", i)\n",
    "        states[:, i] = tmp_state\n",
    "        for j in range(num_samples):\n",
    "            obs[j, i] = np.random.multinomial(1, obs_mat[tmp_state[j]]).argmax()\n",
    "            tmp_state[j] = np.random.multinomial(1, trans_mat[tmp_state[j]]).argmax()\n",
    "        #print(\"obs[:, i]: \", obs[:, i])\n",
    "    return states, obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_compute(trans_mat, obs_mat, init_dist, obs_to_pos):\n",
    "    # compute \\sum_{h_1,...,h_{pos-1}} P(h_1,...,h_{pos},x_1,...,x_{pos-1})\n",
    "    pos = obs_to_pos.shape[0] + 1\n",
    "    num_hidden_state = trans_mat.shape[0]\n",
    "    num_obs = obs_mat.shape[1]\n",
    "    forward = np.zeros((pos, num_hidden_state))\n",
    "    forward[0] = init_dist\n",
    "    for i in range(1, pos):\n",
    "        for j in range(num_hidden_state):\n",
    "            for k in range(num_hidden_state):\n",
    "                #print(i, j, k)\n",
    "                #print(forward[i - 1, k], trans_mat[k, j], obs_mat[k, int(obs_to_pos[i - 1])])\n",
    "                forward[i, j] += forward[i - 1, k] * trans_mat[k, j] * obs_mat[k, int(obs_to_pos[i - 1])]\n",
    "    #print(\"forward: \", forward)\n",
    "    return forward[pos - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_compute(trans_mat, obs_mat, obs_from_pos):\n",
    "    num_hidden_state = trans_mat.shape[0]\n",
    "    num_obs = obs_mat.shape[1]\n",
    "    back_length = obs_from_pos.shape[0]\n",
    "    if (back_length == 0):\n",
    "        return np.ones(num_hidden_state)\n",
    "    backward = np.zeros((back_length, num_hidden_state))\n",
    "    for j in range(num_hidden_state):\n",
    "         for k in range(num_hidden_state):\n",
    "            backward[0, j] += trans_mat[j, k] * obs_mat[k, int(obs_from_pos[-1])]\n",
    "    for i in range(1, back_length):\n",
    "        for j in range(num_hidden_state):\n",
    "            for k in range(num_hidden_state):\n",
    "                backward[i, j] += trans_mat[j, k] * obs_mat[k, int(obs_from_pos[-(i + 1)])] * backward[i - 1, k]\n",
    "    #print(\"backward: \", backward)\n",
    "    return backward[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_i_conditional_prob(trans_mat, obs_mat, init_dist, known_X, pos):\n",
    "    num_hidden_state = trans_mat.shape[0]\n",
    "    num_obs = obs_mat.shape[1]\n",
    "    num_samples = known_X.shape[0]\n",
    "    length = known_X.shape[1]\n",
    "    x_pos_conditional_prob = np.zeros((num_samples, num_obs))\n",
    "    h_pos_conditional_prob = np.zeros((num_samples, num_hidden_state))\n",
    "    h_all_pos_conditional_prob = np.zeros((num_samples, num_hidden_state))\n",
    "    for i in range(num_samples):\n",
    "        #print(\"x_i_conditional_prob: i=\", i)\n",
    "        sample_obs_vec = known_X[i]\n",
    "        forward_vec = forward_compute(trans_mat, obs_mat, init_dist, known_X[i, :pos[i]])\n",
    "        backward_vec = backward_compute(trans_mat, obs_mat, known_X[i, pos[i] + 1:])\n",
    "        #print(\"forward_vec: \", forward_vec)\n",
    "        #print(\"backward_vec: \", backward_vec)\n",
    "        h_prob_tmp = forward_vec * backward_vec\n",
    "        tmp = h_prob_tmp.sum()\n",
    "        h_prob_tmp /= tmp\n",
    "        h_pos_conditional_prob[i] = h_prob_tmp\n",
    "        x_pos_conditional_prob[i] = h_prob_tmp @ obs_mat\n",
    "        h_all_pos_conditional_prob[i] = h_prob_tmp * obs_mat[:, int(known_X[i, pos[i]])] / x_pos_conditional_prob[i, int(known_X[i, pos[i]])]\n",
    "    return h_pos_conditional_prob, x_pos_conditional_prob, h_all_pos_conditional_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transition matrix\n",
      "[[0.19038151 0.5603291  0.24928939]\n",
      " [0.59211519 0.37810341 0.0297814 ]\n",
      " [0.52737761 0.34205379 0.1305686 ]]\n",
      "observation matrix\n",
      "[[2.84422161e-01 2.51497236e-01 1.31816210e-02 4.38026768e-01\n",
      "  1.28722143e-02]\n",
      " [1.50940815e-01 6.59969385e-01 1.64551320e-02 2.15946003e-02\n",
      "  1.51040067e-01]\n",
      " [9.01408117e-03 9.45219115e-01 4.57668030e-02 7.87716140e-11\n",
      "  4.61558184e-10]]\n",
      "stationary distribution\n",
      "[0.41619456 0.44908825 0.1347172 ]\n",
      "states and observations, first half of each row is states, only showing first 5: \n",
      "[[1. 1. 0. 0. 0. 2. 0. 1. 0. 1. 0. 1. 0. 3. 3. 1. 1. 0. 3. 1.]\n",
      " [1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 4. 3. 3. 4. 1. 0. 4. 1. 1.]\n",
      " [0. 2. 0. 2. 0. 2. 2. 2. 1. 0. 3. 1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
      " [0. 2. 2. 0. 1. 0. 2. 1. 2. 0. 1. 1. 1. 3. 1. 0. 1. 1. 1. 2.]\n",
      " [1. 0. 1. 0. 2. 1. 1. 1. 0. 1. 4. 1. 4. 1. 1. 0. 1. 0. 3. 3.]]\n",
      "positions, only showing first 5:  [9 4 6 2 1]\n",
      "Pr[H_i|x_-i], j-th row is for j-th sample and i=positions[j], only showing first 5:\n",
      "[[0.21892801 0.54738046 0.23369153]\n",
      " [0.33619463 0.45004706 0.21375831]\n",
      " [0.60101586 0.31777197 0.08121217]\n",
      " [0.24157682 0.61921196 0.13921122]\n",
      " [0.62919903 0.33535031 0.03545066]]\n",
      "Pr[X_i|x_-i], j-th row is for j-th sample and i=positions[j], only showing first 5:\n",
      "[[0.14699655 0.63720383 0.02258836 0.10771679 0.08549447]\n",
      " [0.16547851 0.58361774 0.02162021 0.15698083 0.07230271]\n",
      " [0.21963904 0.43763689 0.01686816 0.2701232  0.0557327 ]\n",
      " [0.16342902 0.60100195 0.01974484 0.11918875 0.09663544]\n",
      " [0.22989575 0.4130714  0.01543456 0.28284777 0.05875052]]\n",
      "Pr[H_i|x_i,x_-i], j-th row is for j-th sample and i=positions[j], only showing first 5:\n",
      "[[8.64084416e-02 5.66936866e-01 3.46654692e-01]\n",
      " [5.98534890e-02 9.40146510e-01 1.36456714e-09]\n",
      " [3.45386395e-01 4.79209535e-01 1.75404070e-01]\n",
      " [1.01091024e-01 6.79966078e-01 2.18942898e-01]\n",
      " [3.83085874e-01 5.35793431e-01 8.11206949e-02]]\n"
     ]
    }
   ],
   "source": [
    "seed = 20211018\n",
    "np.random.seed(seed)\n",
    "trans_mat, obs_mat, stat_dist = generate_HMM_params(num_hidden_state, num_obs) # generate parameters for HMM\n",
    "\n",
    "states, obs = generate_HMM_sequences(trans_mat, obs_mat, stat_dist, length, num_samples) # generate sample sequences\n",
    "\n",
    "pos = np.random.randint(length, size = num_samples)\n",
    "\n",
    "print(\"transition matrix\")\n",
    "print(trans_mat)\n",
    "print(\"observation matrix\")\n",
    "print(obs_mat)\n",
    "print(\"stationary distribution\")\n",
    "print(stat_dist)\n",
    "print(\"states and observations, first half of each row is states, only showing first 5: \")\n",
    "print(np.concatenate((states, obs), axis = 1)[:5])\n",
    "print(\"positions, only showing first 5: \", pos[:5])\n",
    "h, x, hh = x_i_conditional_prob(trans_mat, obs_mat, stat_dist, obs, pos)\n",
    "print(\"Pr[H_i|x_-i], j-th row is for j-th sample and i=positions[j], only showing first 5:\")\n",
    "print(h[:5])\n",
    "print(\"Pr[X_i|x_-i], j-th row is for j-th sample and i=positions[j], only showing first 5:\")\n",
    "print(x[:5])\n",
    "print(\"Pr[H_i|x_i,x_-i], j-th row is for j-th sample and i=positions[j], only showing first 5:\")\n",
    "print(hh[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "logh = np.log(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linearnetwork = nn.Sequential(\n",
    "            nn.Linear(num_obs, num_hidden_state, bias=False)\n",
    "        )\n",
    "    \n",
    "    def forward(self, logh, ind_x):\n",
    "        logits = self.linearnetwork(ind_x)\n",
    "        return nn.Softmax(dim = 1)(logh + logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 4 6 2 1 3 1 2 1]\n",
      "[[0. 1. 0. 3. 3. 1. 1. 0. 3. 1.]\n",
      " [1. 4. 3. 3. 4. 1. 0. 4. 1. 1.]\n",
      " [3. 1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 3. 1. 0. 1. 1. 1. 2.]\n",
      " [4. 1. 4. 1. 1. 0. 1. 0. 3. 3.]\n",
      " [1. 0. 1. 0. 0. 3. 1. 0. 3. 1.]\n",
      " [0. 0. 1. 1. 1. 1. 1. 1. 1. 3.]\n",
      " [4. 3. 0. 1. 1. 1. 0. 3. 1. 3.]\n",
      " [3. 1. 0. 2. 4. 3. 1. 3. 1. 1.]]\n",
      "[[0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "x_one_hot = np.zeros((num_samples, num_obs))\n",
    "for i in range(num_samples):\n",
    "    x_one_hot[i, int(obs[i, pos[i]])] = 1\n",
    "print(pos[:9])\n",
    "print(obs[:9])\n",
    "print(x_one_hot[:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features1, features2, labels = logh, x_one_hot, hh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters.\n",
    "lr = 1\n",
    "epochs = 1000\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.TensorDataset(torch.FloatTensor(features1), torch.FloatTensor(features2), torch.FloatTensor(labels))\n",
    "train_dl = data.DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = torch.optim.SGD(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "loss:  tensor(0.3448, grad_fn=<AddBackward0>)\n",
      "epoch:  100\n",
      "loss:  tensor(0.0037, grad_fn=<AddBackward0>)\n",
      "epoch:  200\n",
      "loss:  tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "epoch:  300\n",
      "loss:  tensor(0.0011, grad_fn=<AddBackward0>)\n",
      "epoch:  400\n",
      "loss:  tensor(0.0009, grad_fn=<AddBackward0>)\n",
      "epoch:  500\n",
      "loss:  tensor(0.0007, grad_fn=<AddBackward0>)\n",
      "epoch:  600\n",
      "loss:  tensor(0.0006, grad_fn=<AddBackward0>)\n",
      "epoch:  700\n",
      "loss:  tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "epoch:  800\n",
      "loss:  tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "epoch:  900\n",
      "loss:  tensor(0.0004, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "total_loss_lst = []\n",
    "for i in range(epochs):\n",
    "    total_loss = 0\n",
    "    for X1, X2, y in train_dl:\n",
    "        l = loss(net(X1, X2) ,y)\n",
    "        total_loss += l\n",
    "        trainer.zero_grad()\n",
    "        l.backward()\n",
    "        trainer.step()\n",
    "    if (i % 100 == 0):\n",
    "        print(\"epoch: \", i)\n",
    "        print(\"loss: \", total_loss)\n",
    "        total_loss_lst.append(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEGCAYAAAB7DNKzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3de3Rcd3nu8e+r+/02lmRb8k22c7Fzj5NIhKSUkCtxQ2mhhEJ7IJDTFtK0PYc2dHFa2tVzoF0tqwRoSghQsgihKaUkoQkxGEiAxEmcmx07ieNLbMuOLVm2ZUm27u/5Y28pY1saj+0Zzcye57PWrJnZmtnzzk6kx3u/+/fb5u6IiIhMpyDTBYiISHZTUIiISEIKChERSUhBISIiCSkoREQkoaJMF5AOs2bN8oULF2a6DBGRnPLcc8/tc/fGY5dHMigWLlzI2rVrM12GiEhOMbPtUy3XoScREUlIQSEiIgkpKEREJCEFhYiIJBSpoDCzlWZ2d29vb6ZLERGJjEgFhbs/7O631tbWZroUEZHIiFRQiIhI6iko4jz44i7ue3rK04hFRPKWgiLOo+v3cNfPt2S6DBGRrKKgiNPe1kDngSPs3H8406WIiGQNBUWcjsWzAFiztSfDlYiIZA8FRZylTVU0VJawZuv+TJciIpI1IhUUpzuOoqDAaG9rYM3WHnQtcRGRQKSCIhXjKNrbYuw6eITOA0dSWJmISO6KVFCkQntbDICntqhPISICCorjLG2qIlZZooa2iEhIQXEMM6O9LaY+hYhISEExhfbFMXb3DrJD4ylERBQUU+loawA0nkJEBBQUU1rcWMWsqlI1tEVEUFBMKehTNLBm6371KUQk7ykoptHeFmPPoUHe6FGfQkTym4JiGh2Lg/EU6lOISL5TUEyjbVYljdWlCgoRyXuRCopUXjPbzOhoi/HUFo2nEJH8FqmgSPU1s9vbYnT1DbFt30BK1icikosiFRSpNtGneEqHn0QkjykoElgYq6C5plTXpxCRvKagSGBi3if1KUQknykoTqCjLca+/iG2dKtPISL5SUFxApPXp1CfQkTylILiBBbEKphTW6bxFCKStxQUJzDRp3ha16cQkTyloEhC0KcYZnNXf6ZLERGZcQqKJEz0KXT4SUTykYIiCfMayplbW6aGtojkJQVFEsyM9sUxXZ9CRPKSgiJJ7W0x9g8Ms2mv+hQikl8UFEnqUJ9CRPKUgiJJ8xoqaKkrV1CISN5RUJyEjsUx1mztYXxcfQoRyR8KipPQ3hbjwOERNnX1ZboUEZEZk/VBYWZtZvZ1M/tepmtpb2sA4KktOvwkIvkjrUFhZt8wsy4ze/mY5deZ2WtmttnM7ki0Dnff6u63pLPOZLXWVzCvQX0KEckv6d6j+DfguvgFZlYIfAW4HlgG3Gxmy8zsXDP74TG3pjTXd9LaF8V4ett+9SlEJG+kNSjc/Qng2MvDXQpsDvcUhoHvAje5+3p3v/GYW1eyn2Vmt5rZWjNb293dncJvcbSOxTEOHh7h1T3qU4hIfshEj6IF2Bn3vDNcNiUzi5nZvwIXmtmnp3udu9/t7ivcfUVjY2Pqqj2G5n0SkXyTiaCwKZZNexzH3Xvc/Q/cfbG7fy6NdSVlbl05C2IVmvdJRPJGJoKiE5gX97wV2J2KFZvZSjO7u7e3NxWrm1b7ohjPqE8hInkiE0HxLLDUzBaZWQnwAeChVKzY3R9291tra2tTsbpptS9uoPfICBvfPJTWzxERyQbpPj32fuAp4Ewz6zSzW9x9FPgk8BjwCvCAu29IZx2ppj6FiOSTonSu3N1vnmb5I8Ajqf48M1sJrFyyZEmqV32UObXlLIxVsGZrDx+7oi2tnyUikmlZPzL7ZMzUoScITpN9ett+xtSnEJGIi1RQzKT2thh9g6O8oj6FiEScguIUTfQpNO+TiERdpIJipk6PBWiuKaNtVqUa2iISeZEKipnsUQBc1haMpxgdG5+RzxMRyYRIBcVM61gco29oVOMpRCTSFBSnoX2Rrk8hItGnoDgNTTVlLG5Un0JEoi1SQTGTzewJ7W0xnn3jgPoUIhJZkQqKmW5mQ9Cn6B8a5eXd6lOISDRFKigy4bJFmvdJRKJNQXGaGqtLWdJUpYa2iESWgiIFOtpirH1jPyPqU4hIBEUqKDLRzIagoT0wPMb6XTP7uSIiMyFSQZGJZjbAZW3BeAr1KUQkiiIVFJkyq6qUM5rVpxCRaFJQpEjQpzigPoWIRI6CIkXa22IcGRljXaf6FCISLQqKFLlM19EWkYhSUKRIQ2UJZ82uVlCISOREKigydXrshPawTzE8qj6FiERHpIIiU6fHTnirT3EwI58vIpIOkQqKTLtsUQNmuj6FiESLgiKF6itLOGt2DWu2KShEJDoUFCnW3tbAc9sPMDQ6lulSRERSQkGRYh1tMQZHxnlpp8ZTiEg0KChS7NKwT6HTZEUkKk4YFGb2D2ZWY2bFZrbazPaZ2YdmorhcVFdRwtmza9TQFpHISGaP4hp3PwTcCHQCZwCfSmtVOa5jcYzndxxgcER9ChHJfckERXF4fwNwv7vvT2M9pyXTA+4mtLfFGBod58WdGk8hIrkvmaB42MxeBVYAq82sERhMb1mnJtMD7iaoTyEiUXLCoHD3O4AOYIW7jwADwE3pLiyX1ZYXs3yu+hQiEg3JNLPfB4y6+5iZfQb4NjA37ZXluI62GC/sPKg+hYjkvGQOPf0fd+8zs7cD1wLfAu5Kb1m5r70txvDoOC/sUJ9CRHJbMkEx8U/idwN3ufuDQEn6SoqGSxY1UGDwlPoUIpLjkgmKXWb2VeD9wCNmVprk+/JaTVkx57TUqqEtIjkvmT/47wceA65z94NAAxpHkZT2thgv7lCfQkRyWzJnPR0GtgDXmtkngSZ3X5X2yiKgoy3G8Ng4z28/kOlSREROWTJnPd0O3Ac0hbdvm9lt6S4sClYsrKewwNSnEJGcVpTEa24BLnP3AQAz+3vgKeBL6SwsCqrVpxCRCEimR2G8deYT4WNLTznR097WwIs7D3JkWH0KEclNyQTFN4GnzeyzZvZZYA3w9bRWdYqyZa6neO1tMUbGnOfUpxCRHJVMM/sLwEeA/cAB4CPu/s/pLuxUZMtcT/EuWdhAYYHp8JOI5KxpexRm1hD39I3wNvmzbJ5FNptUlRZxbkutGtoikrMSNbOfA5y3+hEe3lv4uC2NdUVKx+IYX3tiK4eHR6koSeb8ARGR7DHtoSd3X+TubeH9xOOJ5wqJk9DeFmN03Fn7hvoUIpJ7NBXHDFixoJ4i9SlEJEcpKGZAZWkR57VqPIWI5CYFxQxpb4uxrrOXgaHRTJciInJSkpnCo2GKW/GJ3idH61gc9ik0nkJEckwyexTPA93AJuD18PE2M3vezC5OZ3FRcvGCeooLTZdHFZGck0xQ/Ai4wd1nuXsMuB54APgj4F/SWVyUVJQUcX5rnfoUIpJzkgmKFe7+2MSTcIrxK919DVCatsoiqL0txvpdvfSrTyEiOSSZoNhvZn9hZgvC258DB8ysEBhPc32R0rE4xti48+wbGtQuIrkjmaD4INAK/AB4EJgfLiskuPqdJOmi+UGfQoefRCSXnHA+CXffB0x3oaLNqS0n2spLCrlgXh1r1NAWkRxywqAwszOA/w0sjH+9u78zfWVFV0dbjC//bDN9gyNUl+ksYxHJfskcevoP4AXgM8Cn4m5yCtrbYow76lOISM5IZirTUXe/K+2VTMPM3gO8m+B63V8Jz7rKWRctqKeksIA1W/fzzrOaM12OiMgJJbNH8bCZ/ZGZzYkfnZ3Mys3sG2bWZWYvH7P8OjN7zcw2m9kdidbh7j9w948D/wP4nWQ+N5uVFRdywfw6DbwTkZyRzB7F74f38Yebkr0exb8BXwbunVgQnlb7FeBqoBN41sweIjiL6nPHvP+j7t4VPv5M+L6c19EW40s/fZ3eIyPUlqtPISLZLZlLoS6a4pbU9Sjc/QmCS6jGuxTY7O5b3X0Y+C5wk7uvd/cbj7l1WeDvgUfd/fnpPsvMbjWztWa2tru7O5nyMmayT7FNfQoRyX6JLoX6Tnf/qZm9d6qfu/v3T/EzW4Cdcc87gcsSvP424F1ArZktcfd/naaeu4G7AVasWOFTvSZbXDi/jpKiAtZs7eFdy9SnEJHslujQ068BPwVWTvEzB041KGyKZdP+YXf3O4E7T/GzslJZcSEXza9jzTb1KUQk+00bFO7+1+H9R1L8mZ3AvLjnrcDuVKzYzFYCK5csWZKK1aVVe1uML65+nd7DI9RWqE8hItkrmetRlJrZB83sL83sryZup/GZzwJLzWyRmZUAHwAeOo31TXL3h9391tra2lSsLq062mK4wzMaTyEiWS6Z02MfBG4CRoGBuNsJmdn9wFPAmWbWaWa3uPso8EngMeAV4AF333AqxeeyC+bXUVpUoNNkRSTrJXN6bKu7X3cqK3f3m6dZ/gjwyKmsMypKiwq5eEG9JggUkayXzB7Fk2Z2btorSQEzW2lmd/f29ma6lKS0t8V4Zc8hDh4eznQpIiLTSiYo3g48F46kXmdm681sXboLOxW51KOAICjc4WmNpxCRLJbMoafr015Fnjp/Xi1lxcF4imuXz850OSIiU0o04K7G3Q8BfTNYT16Z6FOooS0i2SzRoafvhPfPAWvD++finmedXOtRQHCa7Kt7+jgwoD6FiGSnaYPC3W8M7xe5e9upzPU003KtRwFBnwLgaY3SFpEslUyPAjOrB5YCZRPLwgn/5DSd11pHeXEha7bu57pz5mS6HBGR4yRzKdSPAbcTTLXxItBOMIhOl0JNgZKiAlYsVJ9CRLJXMqfH3g5cAmx3918HLgSych7vXOxRQHD46bW9ffT0D2W6FBGR4yQTFIPuPgjBvE/u/ipwZnrLOjW52KOAt/oUz2g8hYhkoWSCotPM6oAfAD82swdJ0WyvEjivtZaKkkKe0nQeIpKFTtijcPffDB9+1sx+BtQCP0prVXmmuLCAFQsbNO+TiGSlhHsUZlZgZi9PPHf3x939ofASppJC7W0NbNrbzz71KUQkyyQMCncfB14ys/kzVE/e6pgYT7FVfQoRyS7J9CjmABvMbLWZPTRxS3dhpyJXz3oCOKellsqSQp7aui/TpYiIHCWZAXd/k/YqUsTdHwYeXrFixcczXcvJeqtPoT0KEckuyexR3BD2JiZvwA3pLiwfdSyOsbmrn66+wUyXIiIyKZmguHqKZZp6PA3a1acQkSw0bVCY2R+a2XqC612vi7ttA7LywkW57py5NVSVFuk0WRHJKol6FN8BHgU+B9wRt7zP3fVP3jQoKizgkoX1GngnIlll2qBw916gF7h55so5PWa2Eli5ZMmSTJdyyjoWx/jZa910HRqkqabsxG8QEUmzZHoUOSNX53qKN9Gn0F6FiGSLSAVFFCybU0NteTFf/ulmNnf1Z7ocEREFRbYpKizgSzdfSM/AMCu/9Ev+Y+1O3D3TZYlIHlNQZKErz2jk0duv4Px5tXzqe+v4swdeon9oNNNliUieUlBkqeaaMu77WDt/dvUZPPjiLm688xe8vCv3piYRkdynoMhihQXGH1+1lPs/3s7gyDjv/Zcn+eavtulQlIjMKAVFDrisLcajt1/BlWfM4m8e3sjH732OAwOa6V1EZoaCIkfUV5bwtd9bwV/duIzHN3Vxw52/0KVTRWRGRCoocnma8WSYGR99+yK+/4eXU1pUwAfufoovrX6dsXEdihKR9IlUUERhwF0yzm2t5eHb3s7K8+fyTz/exIfueZq9hzTjrIikR6SCIp9UlxXzz79zAf/w2+fx4s6D3PDFX/Cz17oyXZaIRJCCIoeZGe9fMY+Hb7ucxupSPvLNZ/l/j7zC8Oh4pksTkQhRUETAkqZqfvCJy/lQ+3zufmIr7/vqU+zoOZzpskQkIhQUEVFWXMjfvedc7vrdi9ja3c+77/wFP1y3O9NliUgEKCgi5vpz5/DIH1/BkuYqPvmdF/j099dzZHgs02WJSA5TUETQvIYKHvifHfzBry3m/md2cNNXfsmmvX2ZLktEcpSCIqKKCwu44/qzuPejl7J/YJjf+PIv+e4zOzT9h4icNAVFxF15RiOP3H4FKxY0cMf313Pb/S9waHAk02WJSA5RUOSBpuoy7v3opXzq2jN59OU93HjnL3lp58FMlyUiOUJBkScKCoxP/PoS/v3WdkbHxvmtu57ka09sZVzTf4jICUQqKKI+11MqrFjYwCO3X8E7z2ri/z7yCrd861l6+ocyXZaIZLFIBUW+zPV0uuoqSvjqhy/mb29azq8293DDnb/gqS09mS5LRLJUpIJCkmdm/F7HQv7rE2+jsqSID96zhi/8eBOjY5r+Q0SOpqDIc8vnBjPR/uaFLdy5+nU+eM/TvNl7JNNliUgWUVAIlaVFfOH9F/BP7zufl3f1cv0Xf8FPNu7NdFkikiUUFDLpty5u5Ye3vZ25teV87N61/O3DG+nTmAuRvGdRHKm7YsUKX7t2babLyFmDI2N8/tFX+bcn36C40Hjb4llcs7yZq5c101RdlunyRCRNzOw5d19x3HIFhUznxZ0H+e91u3lsw1527D+MGVw4r45rl8/mmuWzWTSrMtMlikgKKSjklLk7r+3tY9WGvazauIeXdx0C4IzmKq5ZNptrljdzbkstZpbhSkXkdCgoJGU6Dxzmxxv38tiGPTyzbT/jDnNqy7hmWTPXLp/NJYsaKC5U+0sk1ygoJC32Dwyz+pW9rNq4lyc2dTM0Ok5teTFXnd3ENctm82tnNFJeUpjpMkUkCQoKSbvDw6M8sWkfqzbuYfUrXfQeGaGsuIArljZyzbJm3nV2M/WVJZkuU0SmMV1QFGWiGImmipIirjtnNtedM5uRsXGe3bafVRv3smrDHn68cS+FBcYlC+u5dvlsrl7WTGt9RaZLFpEkaI9C0s7deXnXIR7bsIdVG/ewaW8/AOe01HDNstlcu3w2ZzRXqRkukmE69CRZY9u+AVZt2MNjG/bwws6DuMOCWEVw2u2yZi6cX09hgUJDZKYpKCQrdR0a5CevdPHYhj08uWUfI2POrKpSrl4WNMPftiRGaZGa4SIzQUEhWa9vcISfvdbNqg17+Plr3fQPjVJZUsg7zmziogX1nN9ay7K5NVSUqLUmkg45GxRmdjZwOzALWO3ud53oPQqK3Dc0OsaTW3pYtWEvP3+tizd7BwEoMFjaVM15rbWc11rLua11nDW7mrJi7XWInK6MBIWZfQO4Eehy93Pill8HfBEoBO5x988nsa4C4GvufsuJXqugiJ6uQ4Os6+xl3a5e1nceZF1nLz0DwwAUFRhnzq7mvNa6IDxaajlzdrUG/YmcpEwFxZVAP3DvRFCYWSGwCbga6ASeBW4mCI3PHbOKj7p7l5n9BnAH8GV3/86JPldBEX3uzu7ewcnQWL+rl3WdvfQeCWa7LSkqYNmcmsngOK+1jiVNVWqSiySQsUNPZrYQ+GFcUHQAn3X3a8PnnwZw92NDYqp1/be7v3uan90K3Aowf/78i7dv356S+iV3uDs79h+eDI6Xdh7k5V29DAyPAVBeXMg5LTWc21I3eehqYaySAoWHCJBdA+5agJ1xzzuBy6Z7sZm9A3gvUAo8Mt3r3P1u4G4I9ihSUajkFjNjQaySBbFKVp4/F4DxcWfrvgHWxe15fOeZ7XzjV8ElX6tLizinpTYMjiBAWuvLNaZDJE4mgmKq38Bp/7C7+8+Bn6erGIm2ggJjSVMVS5qqeO9FrQCMjo3zelc/6zt7WbfrIOs7e/nmr95gOLxeeF1FMee21HJ+ax3nhnses2vKFB6StzIRFJ3AvLjnrcDuVKzYzFYCK5csWZKK1UlEFRUWcPacGs6eU8P7Lwn+VxwaHWPTnv7J4Hips5e7Ht/C2Hjwb5hZVaWc21LD0uZqljRWsTgMn9ry4kx+FZEZkYkeRRFBM/sqYBdBM/uD7r4hVZ+pZrakwuDIGBvfPBQGx0E27j7E1n0DDI+OT76mqbqUJU1VLA2DYyJAGqtKtQciOScjPQozux94BzDLzDqBv3b3r5vZJ4HHCM50+kYqQ0IkVcqKC7lofj0Xza+fXDY27uzcf5jNXf283tXP5q5+Nnf385/P76J/aHTydbXlxcEhr8YqljaHAdJYRUtduZrnknOyfsDdqdAehcw0d2fPocEgOOJCZEtX/+R4DwjOvFrcVMmSxqqwd1LNkqYqFsQqNO5DMi5nR2afjLgexcdff/31TJcjAgQXd5oIkIk9kM17+9gdjjYHKC4MztiaOIQ1cVvcWKVR5zJj8iIoJmiPQnLBwNAoW7r7eX1vGB7hHsgbPQOEPXTMoLW+PDyEFTTS2xormR+rUB9EUi6bxlGICFBZWhSO3ag7avnQ6Bhv7Jvog/RN7on8akvPUY30ipJC5jdUML+hggWxCubHKlkQPm+pL9ehLEkZBYVIliktKuTM2dWcObsamDO5fKKRvm3fANt7Bti+/zA7eoLnj4fXK59QWGDMrStjQUOw97FgIkzC51Wl+tWX5EXq/xaNo5AoKywwFs6qZOGsyuN+Nj7udPUNHRUgwf0Aj65/kwOHR456fayyZDJAJvZEgr0SHdKS46lHIZIHeo+MsHP/Ybb3HGb7/oEgSHoOs2P/YXb3HiH+z0B5cXhIK35PJAwTHdKKNvUoRPJYbXkxtS21nNNSe9zPhkbH2HXgyFt7Ij2H2bF/gDf2DfDEMYe0Cgzm1pWzIFbBvPoKWurKmVtXTkt9OS115TTXlFFSpCCJGgWFSJ4rLSqkrbGKtsaq4342Pu509w8FeyI9A+yY3Cs5zE9e2cu+/uGjXm8GzdVlzK0ro6W+grl1ZbTGhcncunJqyjTtSa6JVFCoRyGSWgUFRnNNGc01ZVy6qOG4nw+OjLH74BF2Hxxk98EjdB48wu6DR9h14AjrOg/y2MuDk5MtTqguLZoMjaP3SMpoqaugsbpU1w3JMupRiEjajI87+/qHJgNkIkR2HRxkV/h84mJTE4oKjNm1ZbSEQXJcqNSVU16iQYjpoB6FiMy4ggKjqaaMppqyo+bMitc/NBoXIGGYhPdrtvaw59Dg5ADECQ2VJcHhrbpy5tQGvZHZtaXBfU0Zs2vLqCjRn7dU0ZYUkYyqKi3ijOZqzmiunvLno2Pj7Dk0yO6Dg+w6eDi8D4JlS/cAT27uoS9uQsYJ1WVFk6ExcR8fJM01ZcQqSzRJYxIUFCKS1YoKC2itr6C1vgI4vk8CwXQoew4Nsrd3kDd7B4PHhwbZ0xvcb9rbR3ff0HF7JsWFRlN1Gc01pWGglB+3Z9JcU5b3820pKEQk51WWFrG4MZhEcTqjY+Ps6x9mT1yATDze0zvIq2/28fPXujkcXmM9Xl1FMbNr3tojaa4tY064p9IcBkp9RXFkBypGKih01pOITKeosCDYa6gtO/oam3Hcnb6hUfb2Dk4RKEPsPTTIht2H6BkY4tjzgIoLjVlVpTRVl9JYXUpjdRmN1W89n7ifVVWac3soOutJROQkjYyN09U39FaQ9A7S3T9E16EhuvuH6O4bortvkJ6B4eMCBYIBkFOFSNMx4VJbPrN7KTrrSUQkRYoLCyZP301kdGycnoFhuvuG6OobDO7jwqSrb4gXdhykq2+QwZHx495fUlgQ7IWcIFRmVZWmdUS8gkJEJE2KCgsmByzC8dOnTHB3+odG6ep7K0C6Jx8HAbNz/2Ge337gqCsmxqurKKapupS7P7xiyokjT+t7pHRtIiJy0syM6rJiqsuKEzbkITjs1dN/zF5KXKhUl6X+z7qCQkQkhxTHN+UT7KWkUqSmeTSzlWZ2d29vb6ZLERGJjEgFhbs/7O631tbOTMqKiOSDSAWFiIiknoJCREQSUlCIiEhCCgoREUlIQSEiIgkpKEREJKFITgpoZt3A9lN8+yxgXwrLyXXaHm/RtjiatsfRorA9Frh747ELIxkUp8PM1k41e2K+0vZ4i7bF0bQ9jhbl7aFDTyIikpCCQkREElJQHO/uTBeQZbQ93qJtcTRtj6NFdnuoRyEiIglpj0JERBJSUIiISEIKipCZXWdmr5nZZjO7I9P1zAQzm2dmPzOzV8xsg5ndHi5vMLMfm9nr4X193Hs+HW6j18zs2sxVnx5mVmhmL5jZD8Pn+bwt6szse2b2avj/SEeeb48/DX9PXjaz+82sLF+2h4KC4I8D8BXgemAZcLOZLctsVTNiFPhf7n420A58IvzedwCr3X0psDp8TvizDwDLgeuAfwm3XZTcDrwS9zyft8UXgR+5+1nA+QTbJS+3h5m1AH8MrHD3c4BCgu+bF9tDQRG4FNjs7lvdfRj4LnBThmtKO3d/092fDx/3EfwhaCH47t8KX/Yt4D3h45uA77r7kLtvAzYTbLtIMLNW4N3APXGL83Vb1ABXAl8HcPdhdz9Inm6PUBFQbmZFQAWwmzzZHgqKQAuwM+55Z7gsb5jZQuBC4Gmg2d3fhCBMgKbwZVHfTv8M/DkwHrcsX7dFG9ANfDM8FHePmVWSp9vD3XcB/wjsAN4Eet19FXmyPRQUAZtiWd6cN2xmVcB/An/i7ocSvXSKZZHYTmZ2I9Dl7s8l+5YplkViW4SKgIuAu9z9QmCA8LDKNCK9PcLew03AImAuUGlmH0r0limW5ez2UFAEOoF5cc9bCXYrI8/MiglC4j53/364eK+ZzQl/PgfoCpdHeTtdDvyGmb1BcOjxnWb2bfJzW0Dw/Trd/enw+fcIgiNft8e7gG3u3u3uI8D3gbeRJ9tDQRF4FlhqZovMrISgCfVQhmtKOzMzgmPQr7j7F+J+9BDw++Hj3wcejFv+ATMrNbNFwFLgmZmqN53c/dPu3uruCwn++//U3T9EHm4LAHffA+w0szPDRVcBG8nT7UFwyKndzCrC35urCHp6ebE9ijJdQDZw91Ez+yTwGMHZDN9w9w0ZLmsmXA58GFhvZi+Gy/4S+DzwgJndQvAL8j4Ad99gZg8Q/MEYBT7h7mMzX/aMyudtcRtwX/iPp63ARwj+cZl328Pdnzaz7wHPE3y/Fwim7KgiD7aHpvAQEZGEdOhJREQSUlCIiEhCCgoREUlIQSEiIgkpKEREJCEFhUgWMDsTnVgAAAH4SURBVLN3TMxYK5JtFBQiIpKQgkLkJJjZh8zsGTN70cy+Gl6/ot/M/snMnjez1WbWGL72AjNbY2brzOy/Jq5VYGZLzOwnZvZS+J7F4eqr4q7/cF84Ahgz+7yZbQzX848Z+uqSxxQUIkkys7OB3wEud/cLgDHgd4FK4Hl3vwh4HPjr8C33An/h7ucB6+OW3wd8xd3PJ5gv6M1w+YXAnxBcE6UNuNzMGoDfBJaH6/m79H5LkeMpKESSdxVwMfBsOOXJVQR/0MeBfw9f823g7WZWC9S5++Ph8m8BV5pZNdDi7v8F4O6D7n44fM0z7t7p7uPAi8BC4BAwCNxjZu8FJl4rMmMUFCLJM+Bb7n5BeDvT3T87xesSzYsz1fTTE4biHo8BRe4+SnDBm/8kuCjOj06yZpHTpqAQSd5q4LfNrAkmr6e9gOD36LfD13wQ+KW79wIHzOyKcPmHgcfD6310mtl7wnWUmlnFdB8YXiuk1t0fITgsdUE6vphIIpo9ViRJ7r7RzD4DrDKzAmAE+ATBRX2Wm9lzQC9BHwOCaaf/NQyCidlXIQiNr5rZ34breF+Cj60GHjSzMoK9kT9N8dcSOSHNHitymsys392rMl2HSLro0JOIiCSkPQoREUlIexQiIpKQgkJERBJSUIiISEIKChERSUhBISIiCf1/D4KQyTIn3IAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x_lst = list(range(0, 1000, 100))\n",
    "plt.plot(x_lst, total_loss_lst)\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"training loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learned matrix:\n",
      "[[ 1.2678822  -1.0084215  -0.48770857  2.355959   -0.92696136]\n",
      " [ 0.63277674 -0.04366085 -0.26590344 -0.7576392   1.6483612 ]\n",
      " [-1.3984219   0.3155619   0.7570097  -1.1210496  -1.0172684 ]]\n",
      "log(O):\n",
      "[[ -1.25729566  -1.38032328  -4.32893177  -0.82547526  -4.35268422]\n",
      " [ -1.89086747  -0.41556183  -4.10711787  -3.83531198  -1.89021013]\n",
      " [ -4.70896735  -0.05633851  -3.08419628 -23.26446841 -21.49641299]]\n"
     ]
    }
   ],
   "source": [
    "print(\"learned matrix:\")\n",
    "print(net.linearnetwork[0].weight.data.numpy())\n",
    "print(\"log(O):\")\n",
    "print(np.log(obs_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (linearnetwork): Sequential(\n",
       "    (0): Linear(in_features=5, out_features=3, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transition matrix:\n",
      "[[0.19038151 0.5603291  0.24928939]\n",
      " [0.59211519 0.37810341 0.0297814 ]\n",
      " [0.52737761 0.34205379 0.1305686 ]]\n",
      "observation matrix:\n",
      "[[2.84422161e-01 2.51497236e-01 1.31816210e-02 4.38026768e-01\n",
      "  1.28722143e-02]\n",
      " [1.50940815e-01 6.59969385e-01 1.64551320e-02 2.15946003e-02\n",
      "  1.51040067e-01]\n",
      " [9.01408117e-03 9.45219115e-01 4.57668030e-02 7.87716140e-11\n",
      "  4.61558184e-10]]\n",
      "stationary distribution:\n",
      "[0.41619456 0.44908825 0.1347172 ]\n",
      "states and observations, first half of each row is states, only showing first 5:\n",
      "[[1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 3. 2. 1. 1. 1. 0. 3. 0. 1.]\n",
      " [2. 1. 0. 1. 1. 0. 2. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      " [1. 0. 2. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 3. 1. 3. 1. 1.]\n",
      " [2. 2. 1. 0. 2. 0. 1. 0. 1. 1. 1. 1. 1. 3. 1. 0. 1. 3. 1. 1.]\n",
      " [1. 0. 0. 1. 0. 0. 0. 2. 0. 1. 1. 4. 0. 1. 3. 2. 3. 1. 3. 4.]]\n",
      "positions, only showing first 5:  [4 0 5 4 3]\n",
      "Pr[H_i|x_-i], j-th row is for j-th sample and i=positions[j], only showing first 5:\n",
      "[[0.57212268 0.33122139 0.09665593]\n",
      " [0.49590883 0.37727897 0.12681219]\n",
      " [0.6556958  0.27186427 0.07243993]\n",
      " [0.12064171 0.63288937 0.24646892]\n",
      " [0.13100726 0.65338287 0.21560987]]\n",
      "Pr[X_i|x_-i], j-th row is for j-th sample and i=positions[j], only showing first 5:\n",
      "[[0.21359046 0.45384428 0.01741543 0.25775764 0.05739219]\n",
      " [0.19913735 0.49357758 0.01854885 0.22536853 0.06336769]\n",
      " [0.22818281 0.41279938 0.01643204 0.29308311 0.04950265]\n",
      " [0.1320637  0.6809958  0.02328463 0.06651129 0.09714458]\n",
      " [0.13782704 0.66795922 0.02234616 0.07149423 0.10037335]]\n",
      "Pr[H_i|x_i,x_-i], j-th row is for j-th sample and i=positions[j], only showing first 5:\n",
      "[[3.17041063e-01 4.81654145e-01 2.01304792e-01]\n",
      " [2.52685100e-01 5.04464913e-01 2.42849987e-01]\n",
      " [9.79968821e-01 2.00311791e-02 1.94695980e-11]\n",
      " [4.45539549e-02 6.13348291e-01 3.42097754e-01]\n",
      " [4.93263114e-02 6.45567382e-01 3.05106306e-01]]\n"
     ]
    }
   ],
   "source": [
    "states, obs = generate_HMM_sequences(trans_mat, obs_mat, stat_dist, length, num_samples) # generate sample sequences\n",
    "\n",
    "pos = np.random.randint(length, size = num_samples)\n",
    "\n",
    "print(\"transition matrix:\")\n",
    "print(trans_mat)\n",
    "print(\"observation matrix:\")\n",
    "print(obs_mat)\n",
    "print(\"stationary distribution:\")\n",
    "print(stat_dist)\n",
    "print(\"states and observations, first half of each row is states, only showing first 5:\")\n",
    "print(np.concatenate((states, obs), axis = 1)[:5])\n",
    "print(\"positions, only showing first 5: \", pos[:5])\n",
    "h, x, hh = x_i_conditional_prob(trans_mat, obs_mat, stat_dist, obs, pos)\n",
    "print(\"Pr[H_i|x_-i], j-th row is for j-th sample and i=positions[j], only showing first 5:\")\n",
    "print(h[:5])\n",
    "print(\"Pr[X_i|x_-i], j-th row is for j-th sample and i=positions[j], only showing first 5:\")\n",
    "print(x[:5])\n",
    "print(\"Pr[H_i|x_i,x_-i], j-th row is for j-th sample and i=positions[j], only showing first 5:\")\n",
    "print(hh[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 0 5 4 3 4 8 3 5]\n",
      "[[1. 3. 2. 1. 1. 1. 0. 3. 0. 1.]\n",
      " [1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 0. 1. 3. 1. 3. 1. 1.]\n",
      " [1. 1. 1. 3. 1. 0. 1. 3. 1. 1.]\n",
      " [1. 4. 0. 1. 3. 2. 3. 1. 3. 4.]\n",
      " [1. 3. 1. 1. 3. 1. 3. 1. 1. 0.]\n",
      " [0. 4. 3. 0. 1. 3. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 3. 1. 0. 1. 3.]\n",
      " [1. 1. 3. 1. 1. 1. 3. 1. 3. 1.]]\n",
      "[[0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "x_one_hot = np.zeros((num_samples, num_obs))\n",
    "for i in range(num_samples):\n",
    "    x_one_hot[i, int(obs[i, pos[i]])] = 1\n",
    "print(pos[:9])\n",
    "print(obs[:9])\n",
    "print(x_one_hot[:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "features1, features2, labels = logh, x_one_hot, hh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = data.TensorDataset(torch.FloatTensor(features1), torch.FloatTensor(features2), torch.FloatTensor(labels))\n",
    "test_dl = torch.utils.data.DataLoader(test_dataset, batch_size=num_samples, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04703928393370211\n",
      "tensor([[-0.2306,  0.0853,  0.1453],\n",
      "        [-0.1078,  0.0045,  0.1033],\n",
      "        [-0.0069,  0.0028,  0.0041],\n",
      "        [ 0.0565,  0.0666, -0.1232],\n",
      "        [ 0.3338, -0.1098, -0.2240],\n",
      "        [-0.0163,  0.0112,  0.0051],\n",
      "        [-0.1163,  0.0343,  0.0820],\n",
      "        [-0.2585,  0.0767,  0.1818],\n",
      "        [-0.0449, -0.0686,  0.1135],\n",
      "        [ 0.0255, -0.0305,  0.0050]], grad_fn=<SliceBackward>)\n",
      "0.5878564137803042\n"
     ]
    }
   ],
   "source": [
    "for X1, X2, Y in test_dl:\n",
    "    print(np.linalg.norm((net(X1, X2) - Y).detach().numpy()) ** 2 / num_samples)\n",
    "    print((net(X1, X2)-Y)[:10])\n",
    "    print(np.linalg.norm((Y).detach().numpy()) ** 2 / num_samples)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.5190, -0.6026, -1.4538])\n",
      "tensor([0., 1., 0., 0., 0.])\n",
      "tensor([0.0864, 0.5669, 0.3467], grad_fn=<SelectBackward>)\n",
      "tensor([0.0864, 0.5669, 0.3467])\n",
      "[[ 1.2678822  -1.0084215  -0.48770857  2.355959   -0.92696136]\n",
      " [ 0.63277674 -0.04366085 -0.26590344 -0.7576392   1.6483612 ]\n",
      " [-1.3984219   0.3155619   0.7570097  -1.1210496  -1.0172684 ]]\n",
      "[-2.89933561 -1.01817301 -1.51009174]\n",
      "[-2.5274339  -0.64627206 -1.1381913 ]\n",
      "[-0.37190174 -0.37190098 -0.3719004 ]\n",
      "[[ -1.25729566  -1.38032328  -4.32893177  -0.82547526  -4.35268422]\n",
      " [ -1.89086747  -0.41556183  -4.10711787  -3.83531198  -1.89021013]\n",
      " [ -4.70896735  -0.05633851  -3.08419628 -23.26446841 -21.49641299]]\n"
     ]
    }
   ],
   "source": [
    "for X1, X2, y in train_dl:\n",
    "    print(X1[0])\n",
    "    print(X2[0])\n",
    "    print(net(X1, X2)[0])\n",
    "    print(y[0])\n",
    "    print(net.linearnetwork[0].weight.data.numpy())\n",
    "    print(X2[2].numpy().T @ np.log(obs_mat.T) + X1[0].numpy())\n",
    "    print(X2[2].numpy().T @ net.linearnetwork[0].weight.data.numpy().T + X1[0].numpy())\n",
    "    print(X2[2].numpy().T @ (np.log(obs_mat.T) - net.linearnetwork[0].weight.data.numpy().T))\n",
    "    print(np.log(obs_mat))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transition matrix\n",
      "[[0.19038151 0.5603291  0.24928939]\n",
      " [0.59211519 0.37810341 0.0297814 ]\n",
      " [0.52737761 0.34205379 0.1305686 ]]\n",
      "observation matrix\n",
      "[[2.84422161e-01 2.51497236e-01 1.31816210e-02 4.38026768e-01\n",
      "  1.28722143e-02]\n",
      " [1.50940815e-01 6.59969385e-01 1.64551320e-02 2.15946003e-02\n",
      "  1.51040067e-01]\n",
      " [9.01408117e-03 9.45219115e-01 4.57668030e-02 7.87716140e-11\n",
      "  4.61558184e-10]]\n",
      "stationary distribution\n",
      "[0.41619456 0.44908825 0.1347172 ]\n",
      "states and observations, first half of each row is states\n",
      "[[1. 0. 1. ... 2. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 0.]\n",
      " [1. 1. 0. ... 1. 1. 0.]\n",
      " ...\n",
      " [0. 0. 1. ... 1. 1. 1.]\n",
      " [0. 1. 1. ... 1. 1. 1.]\n",
      " [1. 0. 1. ... 1. 0. 1.]]\n",
      "positions:  [8 3 0 2 1 5 1 6 6 2 2 6 5 5 1 4 7 7 8 6 0 8 5 9 0 2 8 7 1 9 7 9 1 8 2 4 1\n",
      " 1 4 7 6 2 7 3 9 2 7 6 2 5 8 7 8 9 0 1 8 0 0 9 5 4 7 6 7 3 4 9 5 8 3 7 8 3\n",
      " 9 9 0 4 2 6 6 9 1 9 1 5 5 8 1 4 0 3 1 4 7 1 0 6 9 2 2 2 7 4 8 2 7 2 2 6 1\n",
      " 4 7 6 8 0 1 4 2 1 8 7 3 1 7 8 3 1 7 6 3 5 1 9 1 5 8 3 1 7 7 0 8 6 7 4 3 1\n",
      " 8 4 8 8 7 8 1 9 2 1 9 1 7 5 6 7 7 5 4 2 8 6 8 5 2 5 1 1 8 3 8 4 0 4 6 2 4\n",
      " 5 5 7 0 4 9 8 7 8 6 5 3 8 5 5 1 2 1 5 4 4 2 2 6 2 6 5 1 7 5 7 1 1 9 1 5 2\n",
      " 8 5 0 3 6 9 9 1 6 4 7 7 0 1 6 1 4 0 5 5 1 6 2 9 8 8 3 5 1 0 8 2 5 0 4 2 1\n",
      " 1 0 7 0 2 8 0 4 0 3 4 6 9 9 2 4 1 3 0 3 8 1 3 5 3 2 4 0 1 7 9 2 2 3 3 3 8\n",
      " 0 2 1 1 5 1 9 8 9 8 7 7 6 7 2 1 1 8 4 9 0 7 1 5 6 7 7 5 8 9 3 3 4 6 0 0 4\n",
      " 5 8 4 3 1 5 3 0 3 5 9 2 1 6 2 0 9 2 6 5 7 0 6 1 0 0 6 5 0 6 0 1 7 5 5 9 7\n",
      " 2 2 5 0 2 8 7 5 0 9 9 6 8 9 1 2 9 9 7 8 8 5 4 8 6 0 9 0 4 0 5 0 4 9 6 6 5\n",
      " 1 3 3 8 7 8 4 9 3 0 0 6 0 0 2 3 9 5 7 8 9 0 5 1 3 1 9 5 9 0 4 2 6 4 1 2 9\n",
      " 9 3 7 7 8 7 4 1 0 6 9 9 6 7 4 6 3 8 3 0 6 0 7 3 2 9 4 8 2 9 2 5 6 9 2 2 4\n",
      " 7 7 7 4 9 5 8 1 7 4 1 5 4 9 0 6 3 3 2 2 8 9 0 9 1 3 7 6 5 2 7 7 8 6 2 2 6\n",
      " 1 9 3 9 8 0 7 5 2 9 5 6 0 5 0 9 8 6 9 2 2 6 0 3 1 3 3 1 9 6 7 7 5 9 5 7 4\n",
      " 8 4 6 7 1 6 2 6 2 1 7 5 4 0 2 4 7 8 3 0 5 8 2 8 8 6 4 7 5 0 9 3 5 0 7 2 4\n",
      " 6 5 2 7 7 6 9 6 4 9 1 3 1 4 2 3 4 1 5 1 7 7 3 0 4 4 8 7 2 8 8 4 7 3 4 0 3\n",
      " 1 6 5 7 3 4 9 6 6 0 8 9 3 5 5 8 7 5 9 9 6 7 6 8 2 0 7 2 0 1 5 1 0 8 2 1 9\n",
      " 7 6 7 1 9 5 4 1 3 7 0 4 5 0 8 3 4 4 0 1 1 1 3 7 4 5 2 1 0 8 2 2 4 0 4 1 4\n",
      " 8 1 7 1 6 3 7 1 3 4 1 6 8 3 4 9 1 8 2 7 4 3 8 4 7 7 6 9 6 9 0 3 9 0 5 7 8\n",
      " 6 1 8 2 1 3 0 5 9 4 0 8 2 1 3 1 4 7 1 6 0 2 7 9 5 9 7 3 5 8 3 2 8 9 7 6 7\n",
      " 8 6 1 2 8 4 1 8 7 4 9 0 8 4 0 2 6 4 1 1 8 8 2 9 7 2 8 4 3 8 4 5 1 0 2 4 3\n",
      " 0 1 2 3 4 2 4 2 4 3 7 6 2 5 6 0 3 5 1 6 7 3 1 6 3 7 8 1 2 6 6 9 3 4 4 8 1\n",
      " 8 9 2 4 7 5 1 1 2 4 0 1 3 8 4 9 5 6 6 1 2 8 3 1 6 2 2 4 8 5 5 4 6 3 7 8 1\n",
      " 7 7 3 6 5 2 9 3 5 6 0 9 2 2 2 8 4 4 0 3 8 6 1 2 4 3 2 9 1 7 6 0 8 1 5 1 8\n",
      " 0 0 6 0 2 7 6 4 2 3 8 4 9 7 1 9 1 3 5 5 8 4 4 3 5 6 0 0 6 2 3 6 1 2 8 3 2\n",
      " 2 6 8 7 8 5 3 3 7 0 6 0 4 5 6 1 1 2 6 7 9 6 2 4 8 9 4 3 4 5 7 9 9 8 3 4 7\n",
      " 8]\n",
      "Pr[H_i|x_-i], j-th row is for j-th sample and i=positions[j]:\n",
      "[[0.4858475  0.37792806 0.13622444]\n",
      " [0.26856986 0.59572166 0.13570848]\n",
      " [0.49690882 0.37645601 0.12663517]\n",
      " ...\n",
      " [0.6169551  0.29593169 0.08711321]\n",
      " [0.27449065 0.49157009 0.23393927]\n",
      " [0.56377752 0.33707864 0.09914384]]\n",
      "Pr[X_i|x_-i], j-th row is for j-th sample and i=positions[j]:\n",
      "[[0.1964585  0.5003722  0.01885767 0.22097542 0.06333621]\n",
      " [0.16752922 0.58897688 0.01955381 0.13050516 0.09343493]\n",
      " [0.19929596 0.49311862 0.01854038 0.22578878 0.06325626]\n",
      " ...\n",
      " [0.22092912 0.43280943 0.01698896 0.27663338 0.05263912]\n",
      " [0.15437796 0.61457871 0.02241373 0.13084951 0.07778008]\n",
      " [0.21212344 0.45796273 0.01751567 0.25422872 0.05816945]]\n",
      "Pr[H_i|x_i,x_-i], j-th row is for j-th sample and i=positions[j]:\n",
      "[[0.24419683 0.49847084 0.25733233]\n",
      " [0.1146812  0.66752714 0.21779166]\n",
      " [0.25343029 0.50383301 0.2427367 ]\n",
      " ...\n",
      " [0.79426245 0.20218326 0.00355429]\n",
      " [0.11232676 0.52787577 0.35979747]\n",
      " [0.75593165 0.23985528 0.00421307]]\n"
     ]
    }
   ],
   "source": [
    "states, obs = generate_HMM_sequences(trans_mat, obs_mat, stat_dist, length, num_samples) # generate sample sequences\n",
    "\n",
    "pos = np.random.randint(length, size = num_samples)\n",
    "\n",
    "print(\"transition matrix\")\n",
    "print(trans_mat)\n",
    "print(\"observation matrix\")\n",
    "print(obs_mat)\n",
    "print(\"stationary distribution\")\n",
    "print(stat_dist)\n",
    "print(\"states and observations, first half of each row is states\")\n",
    "print(np.concatenate((states, obs), axis = 1))\n",
    "print(\"positions: \", pos)\n",
    "h, x, hh = x_i_conditional_prob(trans_mat, obs_mat, stat_dist, obs, pos)\n",
    "print(\"Pr[H_i|x_-i], j-th row is for j-th sample and i=positions[j]:\")\n",
    "print(h)\n",
    "print(\"Pr[X_i|x_-i], j-th row is for j-th sample and i=positions[j]:\")\n",
    "print(x)\n",
    "print(\"Pr[H_i|x_i,x_-i], j-th row is for j-th sample and i=positions[j]:\")\n",
    "print(hh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "logh = np.log(h)\n",
    "x_one_hot = np.zeros((num_samples, num_obs))\n",
    "for i in range(num_samples):\n",
    "    x_one_hot[i, int(obs[i, pos[i]])] = 1\n",
    "features1, features2, labels = logh, x_one_hot, hh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = data.TensorDataset(torch.FloatTensor(features1), torch.FloatTensor(features2), torch.FloatTensor(labels))\n",
    "test_dl = data.DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0864, 0.5669, 0.3467],\n",
      "        [0.0515, 0.9163, 0.0322],\n",
      "        [0.3454, 0.4792, 0.1754],\n",
      "        [0.1011, 0.6800, 0.2189],\n",
      "        [0.3831, 0.5358, 0.0811],\n",
      "        [0.6893, 0.3025, 0.0082],\n",
      "        [0.6368, 0.3457, 0.0175],\n",
      "        [0.4828, 0.4859, 0.0313],\n",
      "        [0.0514, 0.6097, 0.3388]], grad_fn=<SliceBackward>)\n",
      "tensor([[8.6408e-02, 5.6694e-01, 3.4665e-01],\n",
      "        [5.9853e-02, 9.4015e-01, 1.3646e-09],\n",
      "        [3.4539e-01, 4.7921e-01, 1.7540e-01],\n",
      "        [1.0109e-01, 6.7997e-01, 2.1894e-01],\n",
      "        [3.8309e-01, 5.3579e-01, 8.1121e-02],\n",
      "        [6.9207e-01, 3.0419e-01, 3.7369e-03],\n",
      "        [6.4259e-01, 3.4938e-01, 8.0260e-03],\n",
      "        [4.9077e-01, 4.9475e-01, 1.4478e-02],\n",
      "        [5.1444e-02, 6.0975e-01, 3.3881e-01]])\n"
     ]
    }
   ],
   "source": [
    "for X1, X2, y in test_dl:\n",
    "    print(net(X1, X2)[:9])\n",
    "    print(y[:9])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
