{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameter setting\n",
    "num_hidden_state = 3\n",
    "num_obs = 5\n",
    "length = 3\n",
    "num_samples = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define some useful functions\n",
    "def generate_HMM_params(num_hidden_state, num_obs):\n",
    "    # random generate the transition matrix and observation matrix, and compute the stationary distribution\n",
    "    \n",
    "    alpha_state = np.ones(num_hidden_state)\n",
    "    alpha_obs = np.ones(num_obs) / num_obs\n",
    "    trans_mat = np.random.dirichlet(alpha_state, num_hidden_state)\n",
    "    obs_mat = np.random.dirichlet(alpha_obs, num_hidden_state)\n",
    "    tmp = np.ones((num_hidden_state + 1, num_hidden_state))\n",
    "    tmp[:-1] = np.identity(num_hidden_state) - trans_mat.T\n",
    "    tmp_v = np.zeros(num_hidden_state + 1)\n",
    "    tmp_v[-1] = 1\n",
    "    stat_dist = np.linalg.lstsq(tmp, tmp_v, rcond=None)[0]\n",
    "    return trans_mat, obs_mat, stat_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_HMM_sequences(trans_mat, obs_mat, init_dist, length, num_samples = 1):\n",
    "    # generate sample sequences from HMM\n",
    "    \n",
    "    states = np.zeros((num_samples, length))\n",
    "    obs = np.zeros((num_samples, length))\n",
    "    tmp_state = np.argmax(np.random.multinomial(1, init_dist, num_samples), axis = 1)\n",
    "    #print(tmp_state)\n",
    "    for i in range(length):\n",
    "        #print(\"i: \", i)\n",
    "        states[:, i] = tmp_state\n",
    "        for j in range(num_samples):\n",
    "            obs[j, i] = np.random.multinomial(1, obs_mat[tmp_state[j]]).argmax()\n",
    "            tmp_state[j] = np.random.multinomial(1, trans_mat[tmp_state[j]]).argmax()\n",
    "        #print(\"obs[:, i]: \", obs[:, i])\n",
    "    return states, obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_compute(trans_mat, obs_mat, init_dist, obs_to_pos):\n",
    "    # compute \\sum_{h_1,...,h_{pos-1}} P(h_1,...,h_{pos},x_1,...,x_{pos-1})\n",
    "    pos = obs_to_pos.shape[0] + 1\n",
    "    num_hidden_state = trans_mat.shape[0]\n",
    "    num_obs = obs_mat.shape[1]\n",
    "    forward = np.zeros((pos, num_hidden_state))\n",
    "    forward[0] = init_dist\n",
    "    for i in range(1, pos):\n",
    "        for j in range(num_hidden_state):\n",
    "            for k in range(num_hidden_state):\n",
    "                #print(i, j, k)\n",
    "                #print(forward[i - 1, k], trans_mat[k, j], obs_mat[k, int(obs_to_pos[i - 1])])\n",
    "                forward[i, j] += forward[i - 1, k] * trans_mat[k, j] * obs_mat[k, int(obs_to_pos[i - 1])]\n",
    "    #print(\"forward: \", forward)\n",
    "    return forward[pos - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_compute(trans_mat, obs_mat, obs_from_pos):\n",
    "    num_hidden_state = trans_mat.shape[0]\n",
    "    num_obs = obs_mat.shape[1]\n",
    "    back_length = obs_from_pos.shape[0]\n",
    "    if (back_length == 0):\n",
    "        return np.ones(num_hidden_state)\n",
    "    backward = np.zeros((back_length, num_hidden_state))\n",
    "    for j in range(num_hidden_state):\n",
    "         for k in range(num_hidden_state):\n",
    "            backward[0, j] += trans_mat[j, k] * obs_mat[k, int(obs_from_pos[-1])]\n",
    "    for i in range(1, back_length):\n",
    "        for j in range(num_hidden_state):\n",
    "            for k in range(num_hidden_state):\n",
    "                backward[i, j] += trans_mat[j, k] * obs_mat[k, int(obs_from_pos[-(i + 1)])] * backward[i - 1, k]\n",
    "    #print(\"backward: \", backward)\n",
    "    return backward[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_i_conditional_prob(trans_mat, obs_mat, init_dist, known_X, pos):\n",
    "    num_hidden_state = trans_mat.shape[0]\n",
    "    num_obs = obs_mat.shape[1]\n",
    "    num_samples = known_X.shape[0]\n",
    "    length = known_X.shape[1]\n",
    "    x_pos_conditional_prob = np.zeros((num_samples, num_obs))\n",
    "    h_pos_conditional_prob = np.zeros((num_samples, num_hidden_state))\n",
    "    h_all_pos_conditional_prob = np.zeros((num_samples, num_hidden_state))\n",
    "    for i in range(num_samples):\n",
    "        #print(\"x_i_conditional_prob: i=\", i)\n",
    "        sample_obs_vec = known_X[i]\n",
    "        forward_vec = forward_compute(trans_mat, obs_mat, init_dist, known_X[i, :pos[i]])\n",
    "        backward_vec = backward_compute(trans_mat, obs_mat, known_X[i, pos[i] + 1:])\n",
    "        #print(\"forward_vec: \", forward_vec)\n",
    "        #print(\"backward_vec: \", backward_vec)\n",
    "        h_prob_tmp = forward_vec * backward_vec\n",
    "        tmp = h_prob_tmp.sum()\n",
    "        h_prob_tmp /= tmp\n",
    "        h_pos_conditional_prob[i] = h_prob_tmp\n",
    "        x_pos_conditional_prob[i] = h_prob_tmp @ obs_mat\n",
    "        h_all_pos_conditional_prob[i] = h_prob_tmp * obs_mat[:, int(known_X[i, pos[i]])] / x_pos_conditional_prob[i, int(known_X[i, pos[i]])]\n",
    "    return h_pos_conditional_prob, x_pos_conditional_prob, h_all_pos_conditional_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transition matrix\n",
      "[[0.49723535 0.47180762 0.03095703]\n",
      " [0.37852201 0.50632584 0.11515216]\n",
      " [0.5253994  0.11642175 0.35817885]]\n",
      "observation matrix\n",
      "[[4.51351361e-04 4.05187237e-02 1.33331734e-01 1.23057687e-01\n",
      "  7.02640504e-01]\n",
      " [8.06260940e-06 3.22726641e-01 6.39043461e-01 3.82209436e-02\n",
      "  8.91509141e-07]\n",
      " [2.75679296e-01 4.11532475e-06 9.71653088e-04 8.84559138e-02\n",
      "  6.34889022e-01]]\n",
      "stationary distribution\n",
      "[0.44658521 0.45096487 0.10244993]\n",
      "states and observations, first half of each row is states\n",
      "[[2. 2. 0. 4. 4. 2.]\n",
      " [0. 0. 1. 4. 4. 2.]\n",
      " [0. 1. 2. 4. 2. 4.]\n",
      " [0. 1. 1. 2. 1. 2.]\n",
      " [1. 0. 1. 2. 4. 1.]\n",
      " [0. 0. 0. 4. 4. 4.]\n",
      " [1. 0. 0. 2. 4. 4.]\n",
      " [0. 0. 1. 4. 4. 2.]\n",
      " [1. 1. 2. 2. 2. 4.]\n",
      " [2. 2. 0. 4. 4. 4.]\n",
      " [0. 1. 0. 4. 2. 4.]\n",
      " [1. 0. 1. 2. 4. 2.]\n",
      " [0. 0. 1. 4. 4. 3.]\n",
      " [1. 1. 1. 2. 2. 2.]\n",
      " [0. 1. 0. 4. 2. 4.]\n",
      " [1. 1. 1. 1. 2. 2.]\n",
      " [0. 1. 1. 4. 2. 1.]\n",
      " [0. 0. 1. 4. 4. 2.]\n",
      " [1. 0. 1. 2. 4. 2.]\n",
      " [1. 0. 0. 1. 4. 4.]\n",
      " [1. 0. 0. 2. 4. 4.]\n",
      " [2. 0. 0. 4. 4. 4.]\n",
      " [1. 0. 1. 2. 4. 2.]\n",
      " [0. 0. 0. 4. 2. 2.]\n",
      " [0. 0. 1. 4. 4. 2.]\n",
      " [1. 0. 0. 1. 4. 3.]\n",
      " [2. 2. 0. 4. 4. 4.]\n",
      " [0. 1. 1. 4. 2. 1.]\n",
      " [2. 0. 1. 0. 2. 2.]\n",
      " [1. 2. 2. 2. 4. 0.]\n",
      " [1. 1. 0. 1. 1. 4.]\n",
      " [0. 1. 1. 3. 2. 2.]\n",
      " [1. 1. 0. 2. 2. 4.]\n",
      " [1. 2. 0. 2. 4. 4.]\n",
      " [1. 0. 0. 2. 4. 1.]\n",
      " [1. 0. 1. 1. 3. 2.]\n",
      " [0. 1. 1. 4. 2. 2.]\n",
      " [0. 1. 1. 4. 2. 2.]\n",
      " [2. 0. 1. 4. 4. 3.]\n",
      " [0. 1. 1. 4. 2. 2.]\n",
      " [0. 0. 0. 4. 4. 1.]\n",
      " [0. 0. 1. 4. 2. 2.]\n",
      " [0. 0. 1. 4. 1. 1.]\n",
      " [1. 1. 0. 1. 1. 4.]\n",
      " [1. 2. 2. 1. 0. 4.]\n",
      " [0. 1. 1. 4. 2. 2.]\n",
      " [1. 1. 0. 1. 2. 4.]\n",
      " [2. 0. 1. 4. 4. 1.]\n",
      " [0. 0. 1. 4. 3. 1.]\n",
      " [1. 1. 0. 1. 2. 4.]\n",
      " [1. 2. 0. 2. 4. 4.]\n",
      " [0. 0. 1. 4. 2. 1.]\n",
      " [0. 0. 0. 4. 4. 3.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 2. 0. 2. 0. 2.]\n",
      " [0. 0. 1. 4. 4. 2.]\n",
      " [0. 2. 2. 2. 0. 3.]\n",
      " [0. 0. 0. 4. 2. 4.]\n",
      " [0. 0. 0. 4. 4. 4.]\n",
      " [0. 1. 0. 4. 1. 4.]\n",
      " [2. 2. 2. 4. 0. 4.]\n",
      " [0. 0. 1. 4. 4. 2.]\n",
      " [1. 0. 1. 1. 4. 2.]\n",
      " [0. 1. 0. 0. 2. 4.]\n",
      " [1. 2. 0. 1. 4. 4.]\n",
      " [1. 0. 1. 2. 4. 1.]\n",
      " [0. 0. 1. 4. 4. 1.]\n",
      " [0. 0. 0. 1. 4. 4.]\n",
      " [1. 0. 0. 2. 4. 4.]\n",
      " [2. 2. 0. 0. 3. 4.]\n",
      " [1. 0. 0. 2. 4. 4.]\n",
      " [1. 1. 0. 2. 2. 4.]\n",
      " [0. 0. 0. 4. 4. 1.]\n",
      " [1. 1. 1. 2. 1. 2.]\n",
      " [1. 1. 1. 2. 1. 1.]\n",
      " [1. 1. 1. 1. 2. 2.]\n",
      " [1. 0. 0. 1. 2. 3.]\n",
      " [1. 0. 1. 2. 4. 1.]\n",
      " [0. 1. 1. 4. 2. 2.]\n",
      " [2. 0. 0. 4. 3. 4.]\n",
      " [0. 1. 0. 2. 1. 4.]\n",
      " [1. 2. 2. 1. 4. 0.]\n",
      " [2. 0. 0. 4. 4. 4.]\n",
      " [0. 0. 0. 4. 4. 4.]\n",
      " [1. 1. 1. 2. 2. 1.]\n",
      " [0. 1. 0. 4. 1. 3.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 0. 2. 1. 4.]\n",
      " [0. 0. 1. 4. 3. 1.]\n",
      " [0. 0. 1. 4. 4. 2.]\n",
      " [1. 1. 1. 2. 2. 2.]\n",
      " [0. 0. 1. 4. 4. 1.]\n",
      " [0. 1. 1. 4. 2. 2.]\n",
      " [0. 0. 0. 4. 3. 1.]\n",
      " [2. 2. 0. 4. 4. 4.]\n",
      " [1. 1. 2. 2. 1. 0.]\n",
      " [1. 1. 0. 2. 2. 4.]\n",
      " [1. 0. 0. 2. 4. 4.]\n",
      " [0. 0. 0. 3. 4. 1.]\n",
      " [0. 0. 0. 4. 4. 2.]]\n",
      "positions:  [2 1 0 0 1 1 2 1 1 2 1 1 1 2 2 1 1 2 1 1 1 2 1 2 1 1 2 2 1 0 2 2 1 2 2 0 1\n",
      " 2 0 1 2 2 1 0 2 2 1 2 0 0 1 0 1 0 1 2 0 1 2 0 1 1 0 2 1 1 2 0 0 2 2 2 0 2\n",
      " 1 0 1 2 0 2 1 2 2 0 0 1 2 0 2 1 0 2 2 0 0 1 1 0 1 0]\n",
      "Pr[H_i|x_-i], j-th row is for j-th sample and i=positions[j]:\n",
      "[[0.50105331 0.42362967 0.07531702]\n",
      " [0.52616259 0.4378884  0.03594901]\n",
      " [0.47256746 0.48355568 0.04387686]\n",
      " [0.47049389 0.49280973 0.03669638]\n",
      " [0.41900836 0.54483895 0.03615269]\n",
      " [0.49204267 0.36990227 0.13805506]\n",
      " [0.502471   0.4057401  0.0917889 ]\n",
      " [0.52616259 0.4378884  0.03594901]\n",
      " [0.39047476 0.4499965  0.15952874]\n",
      " [0.50105331 0.42362967 0.07531702]\n",
      " [0.49204267 0.36990227 0.13805506]\n",
      " [0.42100561 0.53711008 0.0418843 ]\n",
      " [0.50676447 0.38507663 0.1081589 ]\n",
      " [0.39548737 0.50130165 0.10321098]\n",
      " [0.40267498 0.49921368 0.09811134]\n",
      " [0.41468745 0.54119648 0.04411607]\n",
      " [0.52425071 0.44468507 0.03106423]\n",
      " [0.50105331 0.42362967 0.07531702]\n",
      " [0.42100561 0.53711008 0.0418843 ]\n",
      " [0.38229654 0.45068716 0.1670163 ]\n",
      " [0.39047476 0.4499965  0.15952874]\n",
      " [0.50105331 0.42362967 0.07531702]\n",
      " [0.42100561 0.53711008 0.0418843 ]\n",
      " [0.40267498 0.49921368 0.09811134]\n",
      " [0.52616259 0.4378884  0.03594901]\n",
      " [0.39620757 0.47212214 0.1316703 ]\n",
      " [0.50105331 0.42362967 0.07531702]\n",
      " [0.40267498 0.49921368 0.09811134]\n",
      " [0.66792599 0.15392805 0.17814596]\n",
      " [0.2433653  0.46957619 0.28705851]\n",
      " [0.38910346 0.50324822 0.10764832]\n",
      " [0.40040332 0.49987983 0.09971685]\n",
      " [0.39047476 0.4499965  0.15952874]\n",
      " [0.502471   0.4057401  0.0917889 ]\n",
      " [0.502471   0.4057401  0.0917889 ]\n",
      " [0.47332405 0.41668598 0.10998997]\n",
      " [0.52616259 0.4378884  0.03594901]\n",
      " [0.40267498 0.49921368 0.09811134]\n",
      " [0.42364447 0.4075526  0.16880292]\n",
      " [0.52616259 0.4378884  0.03594901]\n",
      " [0.50105331 0.42362967 0.07531702]\n",
      " [0.40267498 0.49921368 0.09811134]\n",
      " [0.52425071 0.44468507 0.03106423]\n",
      " [0.47080086 0.49153558 0.03766356]\n",
      " [0.52520956 0.11861532 0.35617512]\n",
      " [0.40267498 0.49921368 0.09811134]\n",
      " [0.38229654 0.45068716 0.1670163 ]\n",
      " [0.50105331 0.42362967 0.07531702]\n",
      " [0.47540744 0.41652143 0.10807113]\n",
      " [0.47256746 0.48355568 0.04387686]\n",
      " [0.39047476 0.4499965  0.15952874]\n",
      " [0.47218057 0.48570634 0.04211309]\n",
      " [0.50676447 0.38507663 0.1081589 ]\n",
      " [0.47043889 0.49303737 0.03652375]\n",
      " [0.42100561 0.53711008 0.0418843 ]\n",
      " [0.50105331 0.42362967 0.07531702]\n",
      " [0.13706589 0.50615845 0.35677566]\n",
      " [0.49204267 0.36990227 0.13805506]\n",
      " [0.50105331 0.42362967 0.07531702]\n",
      " [0.47080086 0.49153558 0.03766356]\n",
      " [0.49204267 0.36990227 0.13805506]\n",
      " [0.52616259 0.4378884  0.03594901]\n",
      " [0.46990286 0.39163782 0.13845931]\n",
      " [0.43564627 0.48889594 0.07545779]\n",
      " [0.38229654 0.45068716 0.1670163 ]\n",
      " [0.41900836 0.54483895 0.03615269]\n",
      " [0.50105331 0.42362967 0.07531702]\n",
      " [0.40630367 0.41351856 0.18017778]\n",
      " [0.40630367 0.41351856 0.18017778]\n",
      " [0.50067868 0.36223201 0.13708931]\n",
      " [0.502471   0.4057401  0.0917889 ]\n",
      " [0.39548737 0.50130165 0.10321098]\n",
      " [0.47329092 0.39047219 0.13623689]\n",
      " [0.38932428 0.50318406 0.10749167]\n",
      " [0.41900836 0.54483895 0.03615269]\n",
      " [0.47225477 0.48537721 0.04236802]\n",
      " [0.39620757 0.47212214 0.1316703 ]\n",
      " [0.502471   0.4057401  0.0917889 ]\n",
      " [0.47225477 0.48537721 0.04236802]\n",
      " [0.47790501 0.44601466 0.07608033]\n",
      " [0.39047476 0.4499965  0.15952874]\n",
      " [0.50276276 0.40205851 0.09517873]\n",
      " [0.50105331 0.42362967 0.07531702]\n",
      " [0.40630367 0.41351856 0.18017778]\n",
      " [0.47218057 0.48570634 0.04211309]\n",
      " [0.50676447 0.38507663 0.1081589 ]\n",
      " [0.38910346 0.50324822 0.10764832]\n",
      " [0.47080086 0.49153558 0.03766356]\n",
      " [0.47790501 0.44601466 0.07608033]\n",
      " [0.52616259 0.4378884  0.03594901]\n",
      " [0.47225477 0.48537721 0.04236802]\n",
      " [0.50105331 0.42362967 0.07531702]\n",
      " [0.40267498 0.49921368 0.09811134]\n",
      " [0.47540744 0.41652143 0.10807113]\n",
      " [0.40630367 0.41351856 0.18017778]\n",
      " [0.11871116 0.5423942  0.33889464]\n",
      " [0.39047476 0.4499965  0.15952874]\n",
      " [0.40630367 0.41351856 0.18017778]\n",
      " [0.49501966 0.47463918 0.03034116]\n",
      " [0.46990286 0.39163782 0.13845931]]\n",
      "Pr[X_i|x_-i], j-th row is for j-th sample and i=positions[j]:\n",
      "[[0.02099291 0.15701893 0.33759726 0.08451222 0.39987867]\n",
      " [0.01015141 0.16263784 0.35001882 0.08466476 0.39252717]\n",
      " [0.01231313 0.17520431 0.37206397 0.08051618 0.3599024 ]\n",
      " [0.01033276 0.17810679 0.37769426 0.07997955 0.35388663]\n",
      " [0.01016006 0.19281188 0.40407801 0.07558438 0.31736567]\n",
      " [0.03828399 0.13931483 0.30212267 0.08689943 0.43337908]\n",
      " [0.02553436 0.151303   0.32637007 0.08545996 0.4113326 ]\n",
      " [0.01015141 0.16263784 0.35001882 0.08466476 0.39252717]\n",
      " [0.04415864 0.16104805 0.339785   0.07936147 0.37564683]\n",
      " [0.02099291 0.15701893 0.33759726 0.08451222 0.39987867]\n",
      " [0.03828399 0.13931483 0.30212267 0.08689943 0.43337908]\n",
      " [0.01174099 0.19039852 0.39941079 0.07604175 0.32240796]\n",
      " [0.030049   0.14480838 0.31375358 0.08664655 0.42474248]\n",
      " [0.02863568 0.17780847 0.37318485 0.0769576  0.34341341]\n",
      " [0.02723304 0.17742584 0.37280392 0.0773112  0.34522601]\n",
      " [0.01235342 0.19146131 0.40118193 0.07561785 0.31938549]\n",
      " [0.00880397 0.16475382 0.35410252 0.08425718 0.38808251]\n",
      " [0.02099291 0.15701893 0.33759726 0.08451222 0.39987867]\n",
      " [0.01174099 0.19039852 0.39941079 0.07604175 0.32240796]\n",
      " [0.04621912 0.16093961 0.33914323 0.0790438  0.37465425]\n",
      " [0.04415864 0.16104805 0.339785   0.07936147 0.37564683]\n",
      " [0.02099291 0.15701893 0.33759726 0.08451222 0.39987867]\n",
      " [0.01174099 0.19039852 0.39941079 0.07604175 0.32240796]\n",
      " [0.02723304 0.17742584 0.37280392 0.0773112  0.34522601]\n",
      " [0.01015141 0.16263784 0.35001882 0.08466476 0.39252717]\n",
      " [0.03648141 0.16842076 0.35466154 0.07844836 0.36198793]\n",
      " [0.02099291 0.15701893 0.33759726 0.08451222 0.39987867]\n",
      " [0.02723304 0.17742584 0.37280392 0.0773112  0.34522601]\n",
      " [0.04941386 0.07674092 0.18759554 0.10383477 0.58241491]\n",
      " [0.07924972 0.16140678 0.33280683 0.07328764 0.35324903]\n",
      " [0.02985609 0.17817803 0.37358192 0.07663892 0.34174503]\n",
      " [0.02767462 0.17754878 0.37292829 0.07719913 0.34464917]\n",
      " [0.04415864 0.16104805 0.339785   0.07936147 0.37564683]\n",
      " [0.02553436 0.151303   0.32637007 0.08545996 0.4113326 ]\n",
      " [0.02553436 0.151303   0.32637007 0.08545996 0.4113326 ]\n",
      " [0.03053895 0.15365461 0.32949644 0.08390156 0.40240845]\n",
      " [0.01015141 0.16263784 0.35001882 0.08466476 0.39252717]\n",
      " [0.02723304 0.17742584 0.37280392 0.0773112  0.34522601]\n",
      " [0.04672997 0.14869431 0.3170931  0.08264137 0.40484125]\n",
      " [0.01015141 0.16263784 0.35001882 0.08466476 0.39252717]\n",
      " [0.02099291 0.15701893 0.33759726 0.08451222 0.39987867]\n",
      " [0.02723304 0.17742584 0.37280392 0.0773112  0.34522601]\n",
      " [0.00880397 0.16475382 0.35410252 0.08425718 0.38808251]\n",
      " [0.01059952 0.17770803 0.37692189 0.08005418 0.35471637]\n",
      " [0.09842812 0.05956261 0.14617352 0.10067046 0.59516529]\n",
      " [0.02723304 0.17742584 0.37280392 0.0773112  0.34522601]\n",
      " [0.04621912 0.16093961 0.33914323 0.0790438  0.37465425]\n",
      " [0.02099291 0.15701893 0.33759726 0.08451222 0.39987867]\n",
      " [0.03001091 0.15368591 0.3296672  0.08398191 0.40265407]\n",
      " [0.01231313 0.17520431 0.37206397 0.08051618 0.3599024 ]\n",
      " [0.04415864 0.16104805 0.339785   0.07936147 0.37564683]\n",
      " [0.01182674 0.1758827  0.37338503 0.08039476 0.35851077]\n",
      " [0.030049   0.14480838 0.31375358 0.08664655 0.42474248]\n",
      " [0.01028515 0.17817803 0.37783223 0.07996622 0.35373838]\n",
      " [0.01174099 0.19039852 0.39941079 0.07604175 0.32240796]\n",
      " [0.02099291 0.15701893 0.33759726 0.08451222 0.39987867]\n",
      " [0.09842161 0.16890602 0.34207914 0.06777178 0.32282145]\n",
      " [0.03828399 0.13931483 0.30212267 0.08689943 0.43337908]\n",
      " [0.02099291 0.15701893 0.33759726 0.08451222 0.39987867]\n",
      " [0.01059952 0.17770803 0.37692189 0.08005418 0.35471637]\n",
      " [0.03828399 0.13931483 0.30212267 0.08689943 0.43337908]\n",
      " [0.01015141 0.16263784 0.35001882 0.08466476 0.39252717]\n",
      " [0.03838562 0.14543239 0.31306109 0.08504147 0.41807943]\n",
      " [0.02100272 0.17543189 0.37058455 0.07897037 0.35401047]\n",
      " [0.04621912 0.16093961 0.33914323 0.0790438  0.37465425]\n",
      " [0.01016006 0.19281188 0.40407801 0.07558438 0.31736567]\n",
      " [0.02099291 0.15701893 0.33759726 0.08451222 0.39987867]\n",
      " [0.049858   0.1499171  0.31860457 0.08174165 0.39987867]\n",
      " [0.049858   0.1499171  0.31860457 0.08174165 0.39987867]\n",
      " [0.03802159 0.13718934 0.29837156 0.08758357 0.43883394]\n",
      " [0.02553436 0.151303   0.32637007 0.08545996 0.4113326 ]\n",
      " [0.02863568 0.17780847 0.37318485 0.0769576  0.34341341]\n",
      " [0.03777446 0.14519348 0.31276578 0.08521726 0.41904902]\n",
      " [0.02981301 0.17816627 0.37357021 0.07664979 0.34180073]\n",
      " [0.01016006 0.19281188 0.40407801 0.07558438 0.31736567]\n",
      " [0.01189705 0.17577949 0.37318485 0.08041386 0.35872475]\n",
      " [0.03648141 0.16842076 0.35466154 0.07844836 0.36198793]\n",
      " [0.02553436 0.151303   0.32637007 0.08545996 0.4113326 ]\n",
      " [0.01189705 0.17577949 0.37318485 0.08041386 0.35872475]\n",
      " [0.02119307 0.16330523 0.34881658 0.08258674 0.38409838]\n",
      " [0.04415864 0.16104805 0.339785   0.07936147 0.37564683]\n",
      " [0.02646897 0.15012669 0.32405958 0.085655   0.41368977]\n",
      " [0.02099291 0.15701893 0.33759726 0.08451222 0.39987867]\n",
      " [0.049858   0.1499171  0.31860457 0.08174165 0.39987867]\n",
      " [0.01182674 0.1758827  0.37338503 0.08039476 0.35851077]\n",
      " [0.030049   0.14480838 0.31375358 0.08664655 0.42474248]\n",
      " [0.02985609 0.17817803 0.37358192 0.07663892 0.34174503]\n",
      " [0.01059952 0.17770803 0.37692189 0.08005418 0.35471637]\n",
      " [0.02119307 0.16330523 0.34881658 0.08258674 0.38409838]\n",
      " [0.01015141 0.16263784 0.35001882 0.08466476 0.39252717]\n",
      " [0.01189705 0.17577949 0.37318485 0.08041386 0.35872475]\n",
      " [0.02099291 0.15701893 0.33759726 0.08451222 0.39987867]\n",
      " [0.02723304 0.17742584 0.37280392 0.0773112  0.34522601]\n",
      " [0.03001091 0.15368591 0.3296672  0.08398191 0.40265407]\n",
      " [0.049858   0.1499171  0.31860457 0.08174165 0.39987867]\n",
      " [0.09348419 0.17985648 0.36277072 0.06531637 0.29857224]\n",
      " [0.04415864 0.16104805 0.339785   0.07936147 0.37564683]\n",
      " [0.049858   0.1499171  0.31860457 0.08174165 0.39987867]\n",
      " [0.00859168 0.1732364  0.36934638 0.08174099 0.36708455]\n",
      " [0.03838562 0.14543239 0.31306109 0.08504147 0.41807943]]\n",
      "Pr[H_i|x_i,x_-i], j-th row is for j-th sample and i=positions[j]:\n",
      "[[1.97887585e-01 8.01895642e-01 2.16773125e-04]\n",
      " [9.41853647e-01 9.94533728e-07 5.81453589e-02]\n",
      " [9.22597447e-01 1.19780893e-06 7.74013549e-02]\n",
      " [1.66091395e-01 8.33814200e-01 9.44048113e-05]\n",
      " [9.27675130e-01 1.53050235e-06 7.23233398e-02]\n",
      " [7.97752192e-01 7.60930255e-07 2.02247047e-01]\n",
      " [8.58323585e-01 8.79388129e-07 1.41675535e-01]\n",
      " [9.41853647e-01 9.94533728e-07 5.81453589e-02]\n",
      " [1.53222409e-01 8.46321401e-01 4.56190210e-04]\n",
      " [8.80417915e-01 9.44460782e-07 1.19581140e-01]\n",
      " [2.17146574e-01 7.82409429e-01 4.43997204e-04]\n",
      " [9.17519519e-01 1.48519455e-06 8.24789960e-02]\n",
      " [8.38327355e-01 8.08252877e-07 1.61671837e-01]\n",
      " [1.41299994e-01 8.58431278e-01 2.68728137e-04]\n",
      " [8.19566736e-01 1.28916580e-06 1.80431975e-01]\n",
      " [1.37820257e-01 8.62072895e-01 1.06848075e-04]\n",
      " [1.97398355e-01 8.02516405e-01 8.52398620e-05]\n",
      " [1.97887585e-01 8.01895642e-01 2.16773125e-04]\n",
      " [9.17519519e-01 1.48519455e-06 8.24789960e-02]\n",
      " [7.16973138e-01 1.07243338e-06 2.83025789e-01]\n",
      " [7.30375877e-01 1.06796055e-06 2.69623055e-01]\n",
      " [8.80417915e-01 9.44460782e-07 1.19581140e-01]\n",
      " [9.17519519e-01 1.48519455e-06 8.24789960e-02]\n",
      " [1.44014991e-01 8.55729298e-01 2.55711318e-04]\n",
      " [9.41853647e-01 9.94533728e-07 5.81453589e-02]\n",
      " [7.69062893e-01 1.16274926e-06 2.30935944e-01]\n",
      " [8.80417915e-01 9.44460782e-07 1.19581140e-01]\n",
      " [9.19588530e-02 9.08038871e-01 2.27565512e-06]\n",
      " [4.74722002e-01 5.24355289e-01 9.22708884e-04]\n",
      " [9.74989504e-02 9.01662962e-01 8.38087614e-04]\n",
      " [8.00011185e-01 1.31282199e-06 1.99987502e-01]\n",
      " [1.43154783e-01 8.56585408e-01 2.59809162e-04]\n",
      " [1.53222409e-01 8.46321401e-01 4.56190210e-04]\n",
      " [8.58323585e-01 8.79388129e-07 1.41675535e-01]\n",
      " [1.34561003e-01 8.65436501e-01 2.49658725e-06]\n",
      " [1.24815565e-01 8.75181489e-01 2.94585662e-06]\n",
      " [2.00429711e-01 7.99470495e-01 9.97945451e-05]\n",
      " [1.44014991e-01 8.55729298e-01 2.55711318e-04]\n",
      " [7.35275284e-01 8.97479862e-07 2.64723819e-01]\n",
      " [2.00429711e-01 7.99470495e-01 9.97945451e-05]\n",
      " [1.29296769e-01 8.70701257e-01 1.97399119e-06]\n",
      " [1.44014991e-01 8.55729298e-01 2.55711318e-04]\n",
      " [1.28931578e-01 8.71067646e-01 7.75941814e-07]\n",
      " [1.07346021e-01 8.92653106e-01 8.72204655e-07]\n",
      " [6.20052133e-01 1.77676093e-07 3.79947689e-01]\n",
      " [1.44014991e-01 8.55729298e-01 2.55711318e-04]\n",
      " [1.50297151e-01 8.49224344e-01 4.78505511e-04]\n",
      " [1.29296769e-01 8.70701257e-01 1.97399119e-06]\n",
      " [8.29596788e-01 9.22212616e-07 1.70402290e-01]\n",
      " [1.09288579e-01 8.90710391e-01 1.03061109e-06]\n",
      " [7.30375877e-01 1.06796055e-06 2.69623055e-01]\n",
      " [9.25420456e-01 1.20780653e-06 7.45783366e-02]\n",
      " [8.38327355e-01 8.08252877e-07 1.61671837e-01]\n",
      " [1.06980549e-01 8.93018608e-01 8.43578042e-07]\n",
      " [1.61844528e-02 3.68836848e-04 9.83446710e-01]\n",
      " [1.97887585e-01 8.01895642e-01 2.16773125e-04]\n",
      " [5.34239894e-02 9.45562613e-01 1.01339756e-03]\n",
      " [2.17146574e-01 7.82409429e-01 4.43997204e-04]\n",
      " [8.80417915e-01 9.44460782e-07 1.19581140e-01]\n",
      " [9.32586654e-01 1.23537703e-06 6.74121107e-02]\n",
      " [5.80096660e-03 7.79014347e-05 9.94121132e-01]\n",
      " [9.41853647e-01 9.94533728e-07 5.81453589e-02]\n",
      " [1.30919006e-01 8.69077076e-01 3.91800638e-06]\n",
      " [8.64671361e-01 1.23119297e-06 1.35327408e-01]\n",
      " [7.16973138e-01 1.07243338e-06 2.83025789e-01]\n",
      " [9.27675130e-01 1.53050235e-06 7.23233398e-02]\n",
      " [1.29296769e-01 8.70701257e-01 1.97399119e-06]\n",
      " [1.09813395e-01 8.90181659e-01 4.94600055e-06]\n",
      " [1.70032628e-01 8.29417882e-01 5.49490842e-04]\n",
      " [8.01663421e-01 7.35889172e-07 1.98335843e-01]\n",
      " [8.58323585e-01 8.79388129e-07 1.41675535e-01]\n",
      " [8.09186351e-01 1.30139067e-06 1.90812348e-01]\n",
      " [7.93590615e-01 8.30713138e-07 2.06408555e-01]\n",
      " [1.38954553e-01 8.60765862e-01 2.79584957e-04]\n",
      " [8.80531011e-02 9.11946127e-01 7.71633251e-07]\n",
      " [1.08858891e-01 8.91140117e-01 9.91914227e-07]\n",
      " [1.48950579e-01 8.50688689e-01 3.60732228e-04]\n",
      " [1.34561003e-01 8.65436501e-01 2.49658725e-06]\n",
      " [9.25013744e-01 1.20626807e-06 7.49850493e-02]\n",
      " [8.74243251e-01 1.03521952e-06 1.25755714e-01]\n",
      " [9.82411053e-02 9.01754818e-01 4.07650109e-06]\n",
      " [8.57315811e-03 1.22469476e-04 9.91304372e-01]\n",
      " [8.80417915e-01 9.44460782e-07 1.19581140e-01]\n",
      " [7.13930077e-01 9.21918560e-07 2.86069001e-01]\n",
      " [1.68610546e-01 8.31279864e-01 1.09590120e-04]\n",
      " [1.41797383e-01 8.58199543e-01 3.07377921e-06]\n",
      " [8.84843976e-02 9.11513116e-01 2.48632109e-06]\n",
      " [1.66540330e-01 8.33362579e-01 9.70915023e-05]\n",
      " [1.18576127e-01 8.81421956e-01 1.91723971e-06]\n",
      " [9.41853647e-01 9.94533728e-07 5.81453589e-02]\n",
      " [1.68727503e-01 8.31162184e-01 1.10312683e-04]\n",
      " [1.29296769e-01 8.70701257e-01 1.97399119e-06]\n",
      " [1.44014991e-01 8.55729298e-01 2.55711318e-04]\n",
      " [8.29596788e-01 9.22212616e-07 1.70402290e-01]\n",
      " [7.13930077e-01 9.21918560e-07 2.86069001e-01]\n",
      " [2.67436837e-02 9.73248562e-01 7.75430247e-06]\n",
      " [1.53222409e-01 8.46321401e-01 4.56190210e-04]\n",
      " [1.70032628e-01 8.29417882e-01 5.49490842e-04]\n",
      " [9.47522470e-01 1.15271854e-06 5.24763774e-02]\n",
      " [7.89736972e-01 8.35125265e-07 2.10262193e-01]]\n"
     ]
    }
   ],
   "source": [
    "trans_mat, obs_mat, stat_dist = generate_HMM_params(num_hidden_state, num_obs) # generate parameters for HMM\n",
    "\n",
    "states, obs = generate_HMM_sequences(trans_mat, obs_mat, stat_dist, length, num_samples) # generate sample sequences\n",
    "\n",
    "pos = np.random.randint(length, size = num_samples)\n",
    "\n",
    "print(\"transition matrix\")\n",
    "print(trans_mat)\n",
    "print(\"observation matrix\")\n",
    "print(obs_mat)\n",
    "print(\"stationary distribution\")\n",
    "print(stat_dist)\n",
    "print(\"states and observations, first half of each row is states\")\n",
    "print(np.concatenate((states, obs), axis = 1))\n",
    "print(\"positions: \", pos)\n",
    "h, x, hh = x_i_conditional_prob(trans_mat, obs_mat, stat_dist, obs, pos)\n",
    "print(\"Pr[H_i|x_-i], j-th row is for j-th sample and i=positions[j]:\")\n",
    "print(h)\n",
    "print(\"Pr[X_i|x_-i], j-th row is for j-th sample and i=positions[j]:\")\n",
    "print(x)\n",
    "print(\"Pr[H_i|x_i,x_-i], j-th row is for j-th sample and i=positions[j]:\")\n",
    "print(hh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logh = np.log(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linearnetwork = nn.Sequential(\n",
    "            nn.Linear(num_obs, num_hidden_state, bias=False)\n",
    "        )\n",
    "    \n",
    "    def forward(self, logh, ind_x):\n",
    "        logits = self.linearnetwork(ind_x)\n",
    "        return nn.Softmax(dim = 1)(logh + logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 0 0 1 1 2 1 1]\n",
      "[[4. 4. 2.]\n",
      " [4. 4. 2.]\n",
      " [4. 2. 4.]\n",
      " [2. 1. 2.]\n",
      " [2. 4. 1.]\n",
      " [4. 4. 4.]\n",
      " [2. 4. 4.]\n",
      " [4. 4. 2.]\n",
      " [2. 2. 4.]]\n",
      "[[0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "x_one_hot = np.zeros((num_samples, num_obs))\n",
    "for i in range(num_samples):\n",
    "    x_one_hot[i, int(obs[i, pos[i]])] = 1\n",
    "print(pos[:9])\n",
    "print(obs[:9])\n",
    "print(x_one_hot[:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "features1, features2, labels = logh, x_one_hot, hh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters.\n",
    "lr = 1\n",
    "epochs = 1000\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.TensorDataset(torch.FloatTensor(features1), torch.FloatTensor(features2), torch.FloatTensor(labels))\n",
    "train_dl = data.DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = torch.optim.SGD(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "loss:  tensor(0.5779, grad_fn=<AddBackward0>)\n",
      "epoch:  100\n",
      "loss:  tensor(0.0111, grad_fn=<AddBackward0>)\n",
      "epoch:  200\n",
      "loss:  tensor(0.0043, grad_fn=<AddBackward0>)\n",
      "epoch:  300\n",
      "loss:  tensor(0.0026, grad_fn=<AddBackward0>)\n",
      "epoch:  400\n",
      "loss:  tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "epoch:  500\n",
      "loss:  tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "epoch:  600\n",
      "loss:  tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "epoch:  700\n",
      "loss:  tensor(0.0010, grad_fn=<AddBackward0>)\n",
      "epoch:  800\n",
      "loss:  tensor(0.0009, grad_fn=<AddBackward0>)\n",
      "epoch:  900\n",
      "loss:  tensor(0.0008, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    total_loss = 0\n",
    "    for X1, X2, y in train_dl:\n",
    "        l = loss(net(X1, X2) ,y)\n",
    "        total_loss += l\n",
    "        trainer.zero_grad()\n",
    "        l.backward()\n",
    "        trainer.step()\n",
    "    if (i % 100 == 0):\n",
    "        print(\"epoch: \", i)\n",
    "        print(\"loss: \", total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (linearnetwork): Sequential(\n",
       "    (0): Linear(in_features=5, out_features=3, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1940, 0.8005, 0.0055],\n",
      "        [0.9354, 0.0079, 0.0567],\n",
      "        [0.9151, 0.0096, 0.0753],\n",
      "        [0.1632, 0.8344, 0.0024],\n",
      "        [0.9176, 0.0122, 0.0702],\n",
      "        [0.7959, 0.0061, 0.1980],\n",
      "        [0.8546, 0.0070, 0.1384],\n",
      "        [0.9354, 0.0079, 0.0567],\n",
      "        [0.1492, 0.8392, 0.0115]], grad_fn=<SliceBackward>)\n",
      "tensor([[1.9789e-01, 8.0190e-01, 2.1677e-04],\n",
      "        [9.4185e-01, 9.9453e-07, 5.8145e-02],\n",
      "        [9.2260e-01, 1.1978e-06, 7.7401e-02],\n",
      "        [1.6609e-01, 8.3381e-01, 9.4405e-05],\n",
      "        [9.2768e-01, 1.5305e-06, 7.2323e-02],\n",
      "        [7.9775e-01, 7.6093e-07, 2.0225e-01],\n",
      "        [8.5832e-01, 8.7939e-07, 1.4168e-01],\n",
      "        [9.4185e-01, 9.9453e-07, 5.8145e-02],\n",
      "        [1.5322e-01, 8.4632e-01, 4.5619e-04]])\n"
     ]
    }
   ],
   "source": [
    "for X1, X2, y in train_dl:\n",
    "    print(net(X1, X2)[:9])\n",
    "    print(y[:9])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transition matrix\n",
      "[[0.49723535 0.47180762 0.03095703]\n",
      " [0.37852201 0.50632584 0.11515216]\n",
      " [0.5253994  0.11642175 0.35817885]]\n",
      "observation matrix\n",
      "[[4.51351361e-04 4.05187237e-02 1.33331734e-01 1.23057687e-01\n",
      "  7.02640504e-01]\n",
      " [8.06260940e-06 3.22726641e-01 6.39043461e-01 3.82209436e-02\n",
      "  8.91509141e-07]\n",
      " [2.75679296e-01 4.11532475e-06 9.71653088e-04 8.84559138e-02\n",
      "  6.34889022e-01]]\n",
      "stationary distribution\n",
      "[0.44658521 0.45096487 0.10244993]\n",
      "states and observations, first half of each row is states\n",
      "[[1. 1. 0. 1. 1. 3.]\n",
      " [2. 0. 1. 0. 2. 2.]\n",
      " [0. 0. 0. 2. 4. 4.]\n",
      " [0. 0. 1. 4. 3. 2.]\n",
      " [1. 1. 1. 2. 3. 1.]\n",
      " [1. 2. 0. 1. 4. 4.]\n",
      " [0. 1. 1. 3. 2. 1.]\n",
      " [1. 1. 2. 1. 1. 4.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [2. 2. 2. 4. 0. 0.]\n",
      " [1. 1. 0. 2. 1. 1.]\n",
      " [1. 0. 1. 2. 3. 2.]\n",
      " [1. 1. 0. 2. 2. 4.]\n",
      " [1. 1. 1. 1. 2. 2.]\n",
      " [1. 1. 1. 1. 1. 2.]\n",
      " [0. 0. 0. 4. 4. 4.]\n",
      " [1. 2. 2. 1. 4. 4.]\n",
      " [1. 0. 0. 2. 4. 4.]\n",
      " [0. 0. 0. 4. 4. 1.]\n",
      " [0. 1. 0. 4. 2. 4.]\n",
      " [1. 0. 0. 2. 3. 2.]\n",
      " [2. 1. 1. 4. 1. 2.]\n",
      " [0. 0. 0. 2. 4. 4.]\n",
      " [1. 0. 0. 2. 4. 4.]\n",
      " [0. 1. 0. 4. 2. 4.]\n",
      " [1. 1. 0. 2. 2. 4.]\n",
      " [0. 0. 0. 4. 4. 3.]\n",
      " [0. 1. 0. 4. 3. 4.]\n",
      " [0. 0. 0. 2. 4. 4.]\n",
      " [1. 1. 0. 2. 2. 4.]\n",
      " [1. 0. 0. 1. 2. 2.]\n",
      " [1. 1. 1. 2. 1. 2.]\n",
      " [1. 2. 2. 2. 4. 4.]\n",
      " [0. 0. 0. 1. 4. 4.]\n",
      " [1. 0. 1. 3. 4. 2.]\n",
      " [2. 0. 0. 3. 4. 4.]\n",
      " [2. 0. 1. 3. 4. 1.]\n",
      " [1. 0. 0. 2. 4. 1.]\n",
      " [1. 1. 2. 2. 2. 0.]\n",
      " [1. 0. 0. 1. 4. 4.]\n",
      " [1. 0. 1. 2. 4. 2.]\n",
      " [0. 0. 1. 4. 4. 2.]\n",
      " [0. 1. 0. 4. 2. 3.]\n",
      " [2. 0. 0. 4. 4. 4.]\n",
      " [0. 0. 1. 2. 4. 1.]\n",
      " [2. 0. 0. 0. 2. 4.]\n",
      " [0. 0. 0. 4. 2. 4.]\n",
      " [0. 1. 1. 4. 2. 2.]\n",
      " [1. 0. 0. 1. 4. 4.]\n",
      " [0. 1. 1. 3. 2. 1.]\n",
      " [0. 0. 1. 4. 4. 1.]\n",
      " [1. 1. 1. 2. 2. 1.]\n",
      " [0. 0. 0. 2. 4. 3.]\n",
      " [0. 0. 0. 4. 3. 4.]\n",
      " [0. 1. 0. 4. 2. 4.]\n",
      " [0. 1. 1. 2. 2. 2.]\n",
      " [1. 2. 0. 1. 3. 4.]\n",
      " [1. 0. 0. 1. 4. 4.]\n",
      " [1. 1. 1. 2. 1. 2.]\n",
      " [0. 0. 0. 3. 4. 4.]\n",
      " [0. 0. 1. 4. 2. 1.]\n",
      " [0. 0. 0. 4. 4. 4.]\n",
      " [0. 0. 1. 3. 4. 2.]\n",
      " [1. 1. 0. 2. 1. 4.]\n",
      " [0. 1. 2. 4. 2. 4.]\n",
      " [0. 1. 1. 4. 2. 2.]\n",
      " [0. 0. 0. 4. 4. 4.]\n",
      " [0. 0. 1. 4. 4. 2.]\n",
      " [1. 0. 0. 3. 4. 3.]\n",
      " [1. 0. 1. 2. 4. 1.]\n",
      " [0. 1. 1. 3. 2. 1.]\n",
      " [1. 2. 0. 1. 3. 2.]\n",
      " [1. 0. 0. 2. 4. 3.]\n",
      " [2. 2. 0. 0. 4. 3.]\n",
      " [0. 0. 1. 4. 4. 2.]\n",
      " [0. 1. 1. 2. 3. 3.]\n",
      " [1. 1. 0. 2. 2. 4.]\n",
      " [0. 1. 1. 2. 1. 1.]\n",
      " [1. 1. 0. 2. 2. 4.]\n",
      " [0. 2. 2. 2. 4. 4.]\n",
      " [0. 1. 2. 2. 2. 4.]\n",
      " [1. 2. 2. 2. 4. 4.]\n",
      " [2. 2. 0. 0. 4. 4.]\n",
      " [1. 0. 1. 2. 4. 1.]\n",
      " [1. 0. 0. 2. 4. 4.]\n",
      " [2. 2. 0. 4. 4. 4.]\n",
      " [1. 0. 1. 2. 4. 1.]\n",
      " [1. 1. 1. 2. 2. 1.]\n",
      " [0. 1. 2. 4. 2. 0.]\n",
      " [2. 0. 0. 0. 4. 4.]\n",
      " [2. 2. 0. 0. 4. 4.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 0. 0. 2. 4. 4.]\n",
      " [0. 1. 0. 4. 2. 4.]\n",
      " [1. 0. 0. 2. 2. 4.]\n",
      " [1. 2. 0. 2. 4. 4.]\n",
      " [0. 1. 1. 2. 3. 2.]\n",
      " [1. 1. 0. 1. 2. 2.]\n",
      " [0. 0. 0. 4. 2. 1.]\n",
      " [2. 0. 0. 4. 4. 4.]]\n",
      "positions:  [1 1 0 1 0 0 0 2 0 2 2 1 1 2 1 2 2 0 0 1 1 1 1 0 2 1 1 0 1 2 1 1 0 0 0 1 2\n",
      " 0 0 0 0 1 0 1 2 2 2 1 1 2 0 1 2 2 2 1 0 0 2 2 1 0 1 1 2 2 2 1 1 1 1 1 0 1\n",
      " 2 1 1 0 1 2 0 0 1 1 0 0 0 1 2 1 1 1 0 0 0 2 2 0 1 1]\n",
      "Pr[H_i|x_-i], j-th row is for j-th sample and i=positions[j]:\n",
      "[[0.39620757 0.47212214 0.1316703 ]\n",
      " [0.66792599 0.15392805 0.17814596]\n",
      " [0.40630367 0.41351856 0.18017778]\n",
      " [0.52616259 0.4378884  0.03594901]\n",
      " [0.47540744 0.41652143 0.10807113]\n",
      " [0.40630367 0.41351856 0.18017778]\n",
      " [0.47218057 0.48570634 0.04211309]\n",
      " [0.38910346 0.50324822 0.10764832]\n",
      " [0.47043889 0.49303737 0.03652375]\n",
      " [0.52511618 0.11979563 0.35508818]\n",
      " [0.38932428 0.50318406 0.10749167]\n",
      " [0.42100561 0.53711008 0.0418843 ]\n",
      " [0.39047476 0.4499965  0.15952874]\n",
      " [0.39516225 0.50139175 0.103446  ]\n",
      " [0.41468745 0.54119648 0.04411607]\n",
      " [0.50105331 0.42362967 0.07531702]\n",
      " [0.50276276 0.40205851 0.09517873]\n",
      " [0.40630367 0.41351856 0.18017778]\n",
      " [0.47329092 0.39047219 0.13623689]\n",
      " [0.49204267 0.36990227 0.13805506]\n",
      " [0.42100561 0.53711008 0.0418843 ]\n",
      " [0.52616259 0.4378884  0.03594901]\n",
      " [0.39047476 0.4499965  0.15952874]\n",
      " [0.40630367 0.41351856 0.18017778]\n",
      " [0.40267498 0.49921368 0.09811134]\n",
      " [0.39047476 0.4499965  0.15952874]\n",
      " [0.50676447 0.38507663 0.1081589 ]\n",
      " [0.42955467 0.42660618 0.14383915]\n",
      " [0.39047476 0.4499965  0.15952874]\n",
      " [0.39548737 0.50130165 0.10321098]\n",
      " [0.41468745 0.54119648 0.04411607]\n",
      " [0.42100561 0.53711008 0.0418843 ]\n",
      " [0.40630367 0.41351856 0.18017778]\n",
      " [0.40630367 0.41351856 0.18017778]\n",
      " [0.46990286 0.39163782 0.13845931]\n",
      " [0.46728592 0.39709511 0.13561897]\n",
      " [0.5011663  0.42220372 0.07662998]\n",
      " [0.47329092 0.39047219 0.13623689]\n",
      " [0.4684982  0.49967259 0.03182921]\n",
      " [0.40630367 0.41351856 0.18017778]\n",
      " [0.46990286 0.39163782 0.13845931]\n",
      " [0.52616259 0.4378884  0.03594901]\n",
      " [0.4725606  0.48375152 0.04368788]\n",
      " [0.49204267 0.36990227 0.13805506]\n",
      " [0.502471   0.4057401  0.0917889 ]\n",
      " [0.43564627 0.48889594 0.07545779]\n",
      " [0.40267498 0.49921368 0.09811134]\n",
      " [0.52616259 0.4378884  0.03594901]\n",
      " [0.38229654 0.45068716 0.1670163 ]\n",
      " [0.40040332 0.49987983 0.09971685]\n",
      " [0.47329092 0.39047219 0.13623689]\n",
      " [0.41900836 0.54483895 0.03615269]\n",
      " [0.502471   0.4057401  0.0917889 ]\n",
      " [0.47790501 0.44601466 0.07608033]\n",
      " [0.40267498 0.49921368 0.09811134]\n",
      " [0.42100561 0.53711008 0.0418843 ]\n",
      " [0.42955467 0.42660618 0.14383915]\n",
      " [0.40630367 0.41351856 0.18017778]\n",
      " [0.38932428 0.50318406 0.10749167]\n",
      " [0.5011663  0.42220372 0.07662998]\n",
      " [0.52425071 0.44468507 0.03106423]\n",
      " [0.40630367 0.41351856 0.18017778]\n",
      " [0.49716208 0.46770185 0.03513607]\n",
      " [0.39047476 0.4499965  0.15952874]\n",
      " [0.40267498 0.49921368 0.09811134]\n",
      " [0.40267498 0.49921368 0.09811134]\n",
      " [0.50105331 0.42362967 0.07531702]\n",
      " [0.52616259 0.4378884  0.03594901]\n",
      " [0.48083312 0.41301231 0.10615456]\n",
      " [0.41900836 0.54483895 0.03615269]\n",
      " [0.49501966 0.47463918 0.03034116]\n",
      " [0.41468745 0.54119648 0.04411607]\n",
      " [0.42364447 0.4075526  0.16880292]\n",
      " [0.48933352 0.10296555 0.40770093]\n",
      " [0.50105331 0.42362967 0.07531702]\n",
      " [0.40393636 0.47052846 0.12553518]\n",
      " [0.39047476 0.4499965  0.15952874]\n",
      " [0.47043889 0.49303737 0.03652375]\n",
      " [0.39047476 0.4499965  0.15952874]\n",
      " [0.502471   0.4057401  0.0917889 ]\n",
      " [0.47256746 0.48355568 0.04387686]\n",
      " [0.40630367 0.41351856 0.18017778]\n",
      " [0.43412793 0.09037492 0.47549715]\n",
      " [0.41900836 0.54483895 0.03615269]\n",
      " [0.40630367 0.41351856 0.18017778]\n",
      " [0.40630367 0.41351856 0.18017778]\n",
      " [0.47329092 0.39047219 0.13623689]\n",
      " [0.41900836 0.54483895 0.03615269]\n",
      " [0.40267498 0.49921368 0.09811134]\n",
      " [0.43412793 0.09037492 0.47549715]\n",
      " [0.43412793 0.09037492 0.47549715]\n",
      " [0.41280959 0.5491031  0.0380873 ]\n",
      " [0.40630367 0.41351856 0.18017778]\n",
      " [0.47256746 0.48355568 0.04387686]\n",
      " [0.47256746 0.48355568 0.04387686]\n",
      " [0.502471   0.4057401  0.0917889 ]\n",
      " [0.47105832 0.43927672 0.08966497]\n",
      " [0.47225477 0.48537721 0.04236802]\n",
      " [0.52425071 0.44468507 0.03106423]\n",
      " [0.49204267 0.36990227 0.13805506]]\n",
      "Pr[X_i|x_-i], j-th row is for j-th sample and i=positions[j]:\n",
      "[[0.03648141 0.16842076 0.35466154 0.07844836 0.36198793]\n",
      " [0.04941386 0.07674092 0.18759554 0.10383477 0.58241491]\n",
      " [0.049858   0.1499171  0.31860457 0.08174165 0.39987867]\n",
      " [0.01015141 0.16263784 0.35001882 0.08466476 0.39252717]\n",
      " [0.03001091 0.15368591 0.3296672  0.08398191 0.40265407]\n",
      " [0.049858   0.1499171  0.31860457 0.08174165 0.39987867]\n",
      " [0.01182674 0.1758827  0.37338503 0.08039476 0.35851077]\n",
      " [0.02985609 0.17817803 0.37358192 0.07663892 0.34174503]\n",
      " [0.01028515 0.17817803 0.37783223 0.07996622 0.35373838]\n",
      " [0.09812844 0.05993974 0.14691429 0.10060793 0.5944096 ]\n",
      " [0.02981301 0.17816627 0.37357021 0.07664979 0.34180073]\n",
      " [0.01174099 0.19039852 0.39941079 0.07604175 0.32240796]\n",
      " [0.04415864 0.16104805 0.339785   0.07936147 0.37564683]\n",
      " [0.02870032 0.17782437 0.3731993  0.07694183 0.34333418]\n",
      " [0.01235342 0.19146131 0.40118193 0.07561785 0.31938549]\n",
      " [0.02099291 0.15701893 0.33759726 0.08451222 0.39987867]\n",
      " [0.02646897 0.15012669 0.32405958 0.085655   0.41368977]\n",
      " [0.049858   0.1499171  0.31860457 0.08174165 0.39987867]\n",
      " [0.03777446 0.14519348 0.31276578 0.08521726 0.41904902]\n",
      " [0.03828399 0.13931483 0.30212267 0.08689943 0.43337908]\n",
      " [0.01174099 0.19039852 0.39941079 0.07604175 0.32240796]\n",
      " [0.01015141 0.16263784 0.35001882 0.08466476 0.39252717]\n",
      " [0.04415864 0.16104805 0.339785   0.07936147 0.37564683]\n",
      " [0.049858   0.1499171  0.31860457 0.08174165 0.39987867]\n",
      " [0.02723304 0.17742584 0.37280392 0.0773112  0.34522601]\n",
      " [0.04415864 0.16104805 0.339785   0.07936147 0.37564683]\n",
      " [0.030049   0.14480838 0.31375358 0.08664655 0.42474248]\n",
      " [0.0398508  0.15508278 0.33003292 0.08188872 0.39314478]\n",
      " [0.04415864 0.16104805 0.339785   0.07936147 0.37564683]\n",
      " [0.02863568 0.17780847 0.37318485 0.0769576  0.34341341]\n",
      " [0.01235342 0.19146131 0.40118193 0.07561785 0.31938549]\n",
      " [0.01174099 0.19039852 0.39941079 0.07604175 0.32240796]\n",
      " [0.049858   0.1499171  0.31860457 0.08174165 0.39987867]\n",
      " [0.049858   0.1499171  0.31860457 0.08174165 0.39987867]\n",
      " [0.03838562 0.14543239 0.31306109 0.08504147 0.41807943]\n",
      " [0.03760145 0.14708756 0.31619685 0.08467677 0.41443736]\n",
      " [0.02135491 0.15656332 0.33670235 0.08458777 0.40079165]\n",
      " [0.03777446 0.14519348 0.31276578 0.08521726 0.41904902]\n",
      " [0.00899014 0.18024074 0.3818091  0.07956574 0.34939428]\n",
      " [0.049858   0.1499171  0.31860457 0.08174165 0.39987867]\n",
      " [0.03838562 0.14543239 0.31306109 0.08504147 0.41807943]\n",
      " [0.01015141 0.16263784 0.35001882 0.08466476 0.39252717]\n",
      " [0.01226104 0.17526724 0.37218802 0.08050611 0.3597776 ]\n",
      " [0.03828399 0.13931483 0.30212267 0.08689943 0.43337908]\n",
      " [0.02553436 0.151303   0.32637007 0.08545996 0.4113326 ]\n",
      " [0.02100272 0.17543189 0.37058455 0.07897037 0.35401047]\n",
      " [0.02723304 0.17742584 0.37280392 0.0773112  0.34522601]\n",
      " [0.01015141 0.16263784 0.35001882 0.08466476 0.39252717]\n",
      " [0.04621912 0.16093961 0.33914323 0.0790438  0.37465425]\n",
      " [0.02767462 0.17754878 0.37292829 0.07719913 0.34464917]\n",
      " [0.03777446 0.14519348 0.31276578 0.08521726 0.41904902]\n",
      " [0.01016006 0.19281188 0.40407801 0.07558438 0.31736567]\n",
      " [0.02553436 0.151303   0.32637007 0.08545996 0.4113326 ]\n",
      " [0.02119307 0.16330523 0.34881658 0.08258674 0.38409838]\n",
      " [0.02723304 0.17742584 0.37280392 0.0773112  0.34522601]\n",
      " [0.01174099 0.19039852 0.39941079 0.07604175 0.32240796]\n",
      " [0.0398508  0.15508278 0.33003292 0.08188872 0.39314478]\n",
      " [0.049858   0.1499171  0.31860457 0.08174165 0.39987867]\n",
      " [0.02981301 0.17816627 0.37357021 0.07664979 0.34180073]\n",
      " [0.02135491 0.15656332 0.33670235 0.08458777 0.40079165]\n",
      " [0.00880397 0.16475382 0.35410252 0.08425718 0.38808251]\n",
      " [0.049858   0.1499171  0.31860457 0.08174165 0.39987867]\n",
      " [0.00991445 0.17108436 0.36520343 0.08216361 0.37163414]\n",
      " [0.04415864 0.16104805 0.339785   0.07936147 0.37564683]\n",
      " [0.02723304 0.17742584 0.37280392 0.0773112  0.34522601]\n",
      " [0.02723304 0.17742584 0.37280392 0.0773112  0.34522601]\n",
      " [0.02099291 0.15701893 0.33759726 0.08451222 0.39987867]\n",
      " [0.01015141 0.16263784 0.35001882 0.08466476 0.39252717]\n",
      " [0.02948497 0.15277326 0.32814628 0.08434593 0.40524956]\n",
      " [0.01016006 0.19281188 0.40407801 0.07558438 0.31736567]\n",
      " [0.00859168 0.1732364  0.36934638 0.08174099 0.36708455]\n",
      " [0.01235342 0.19146131 0.40118193 0.07561785 0.31938549]\n",
      " [0.04672997 0.14869431 0.3170931  0.08264137 0.40484125]\n",
      " [0.1126164  0.05305857 0.13143929 0.10021525 0.60267049]\n",
      " [0.02099291 0.15701893 0.33759726 0.08451222 0.39987867]\n",
      " [0.03479356 0.16821957 0.35466764 0.07879585 0.36352338]\n",
      " [0.04415864 0.16104805 0.339785   0.07936147 0.37564683]\n",
      " [0.01028515 0.17817803 0.37783223 0.07996622 0.35373838]\n",
      " [0.04415864 0.16104805 0.339785   0.07936147 0.37564683]\n",
      " [0.02553436 0.151303   0.32637007 0.08545996 0.4113326 ]\n",
      " [0.01231313 0.17520431 0.37206397 0.08051618 0.3599024 ]\n",
      " [0.049858   0.1499171  0.31860457 0.08174165 0.39987867]\n",
      " [0.13128139 0.04675866 0.11609855 0.09893753 0.60692387]\n",
      " [0.01016006 0.19281188 0.40407801 0.07558438 0.31736567]\n",
      " [0.049858   0.1499171  0.31860457 0.08174165 0.39987867]\n",
      " [0.049858   0.1499171  0.31860457 0.08174165 0.39987867]\n",
      " [0.03777446 0.14519348 0.31276578 0.08521726 0.41904902]\n",
      " [0.01016006 0.19281188 0.40407801 0.07558438 0.31736567]\n",
      " [0.02723304 0.17742584 0.37280392 0.0773112  0.34522601]\n",
      " [0.13128139 0.04675866 0.11609855 0.09893753 0.60692387]\n",
      " [0.13128139 0.04675866 0.11609855 0.09893753 0.60692387]\n",
      " [0.01069063 0.19393687 0.40597837 0.07515568 0.31423844]\n",
      " [0.049858   0.1499171  0.31860457 0.08174165 0.39987867]\n",
      " [0.01231313 0.17520431 0.37206397 0.08051618 0.3599024 ]\n",
      " [0.01231313 0.17520431 0.37206397 0.08051618 0.3599024 ]\n",
      " [0.02553436 0.151303   0.32637007 0.08545996 0.4113326 ]\n",
      " [0.02493493 0.16085335 0.34361106 0.08268831 0.38791235]\n",
      " [0.01189705 0.17577949 0.37318485 0.08041386 0.35872475]\n",
      " [0.00880397 0.16475382 0.35410252 0.08425718 0.38808251]\n",
      " [0.03828399 0.13931483 0.30212267 0.08689943 0.43337908]]\n",
      "Pr[H_i|x_i,x_-i], j-th row is for j-th sample and i=positions[j]:\n",
      "[[9.53197528e-02 9.04677030e-01 3.21733514e-06]\n",
      " [4.74722002e-01 5.24355289e-01 9.22708884e-04]\n",
      " [1.70032628e-01 8.29417882e-01 5.49490842e-04]\n",
      " [7.64761512e-01 1.97679736e-01 3.75587513e-02]\n",
      " [1.92275415e-01 8.07406058e-01 3.18526225e-04]\n",
      " [1.09813395e-01 8.90181659e-01 4.94600055e-06]\n",
      " [7.22751737e-01 2.30912509e-01 4.63357537e-02]\n",
      " [8.00011185e-01 1.31282199e-06 1.99987502e-01]\n",
      " [1.06980549e-01 8.93018608e-01 8.43578042e-07]\n",
      " [2.41532331e-03 9.84286950e-06 9.97574834e-01]\n",
      " [8.85404586e-02 9.11457059e-01 2.48286687e-06]\n",
      " [6.81309676e-01 2.69968212e-01 4.87221114e-02]\n",
      " [1.53222409e-01 8.46321401e-01 4.56190210e-04]\n",
      " [1.41178369e-01 8.58552301e-01 2.69329614e-04]\n",
      " [8.77598006e-02 9.12239251e-01 9.48243601e-07]\n",
      " [8.80417915e-01 9.44460782e-07 1.19581140e-01]\n",
      " [8.53928493e-01 8.66443577e-07 1.46070641e-01]\n",
      " [1.70032628e-01 8.29417882e-01 5.49490842e-04]\n",
      " [7.93590615e-01 8.30713138e-07 2.06408555e-01]\n",
      " [2.17146574e-01 7.82409429e-01 4.43997204e-04]\n",
      " [6.81309676e-01 2.69968212e-01 4.87221114e-02]\n",
      " [1.31085343e-01 8.68913747e-01 9.09639864e-07]\n",
      " [7.30375877e-01 1.06796055e-06 2.69623055e-01]\n",
      " [1.70032628e-01 8.29417882e-01 5.49490842e-04]\n",
      " [8.19566736e-01 1.28916580e-06 1.80431975e-01]\n",
      " [1.53222409e-01 8.46321401e-01 4.56190210e-04]\n",
      " [8.38327355e-01 8.08252877e-07 1.61671837e-01]\n",
      " [7.67713369e-01 9.67387407e-07 2.32285664e-01]\n",
      " [7.30375877e-01 1.06796055e-06 2.69623055e-01]\n",
      " [8.09186351e-01 1.30139067e-06 1.90812348e-01]\n",
      " [1.37820257e-01 8.62072895e-01 1.06848075e-04]\n",
      " [8.95942394e-02 9.10404855e-01 9.05298622e-07]\n",
      " [1.70032628e-01 8.29417882e-01 5.49490842e-04]\n",
      " [1.09813395e-01 8.90181659e-01 4.94600055e-06]\n",
      " [6.79964238e-01 1.76017262e-01 1.44018500e-01]\n",
      " [7.92240383e-01 8.54203685e-07 2.07758763e-01]\n",
      " [1.29702274e-01 8.70295712e-01 2.01424736e-06]\n",
      " [2.01763442e-01 7.97813318e-01 4.23240013e-04]\n",
      " [1.63604475e-01 8.36314524e-01 8.10010865e-05]\n",
      " [1.09813395e-01 8.90181659e-01 4.94600055e-06]\n",
      " [2.00130155e-01 7.99440107e-01 4.29738559e-04]\n",
      " [9.41853647e-01 9.94533728e-07 5.81453589e-02]\n",
      " [9.22904075e-01 1.19870970e-06 7.70947267e-02]\n",
      " [7.97752192e-01 7.60930255e-07 2.02247047e-01]\n",
      " [1.34561003e-01 8.65436501e-01 2.49658725e-06]\n",
      " [8.64671361e-01 1.23119297e-06 1.35327408e-01]\n",
      " [8.19566736e-01 1.28916580e-06 1.80431975e-01]\n",
      " [2.00429711e-01 7.99470495e-01 9.97945451e-05]\n",
      " [7.16973138e-01 1.07243338e-06 2.83025789e-01]\n",
      " [9.13767561e-02 9.08620933e-01 2.31129288e-06]\n",
      " [7.93590615e-01 8.30713138e-07 2.06408555e-01]\n",
      " [1.38258231e-01 8.61654836e-01 8.69333922e-05]\n",
      " [7.23530869e-01 1.81462402e-01 9.50067298e-02]\n",
      " [8.74243251e-01 1.03521952e-06 1.25755714e-01]\n",
      " [8.19566736e-01 1.28916580e-06 1.80431975e-01]\n",
      " [1.40540541e-01 8.59357567e-01 1.01892624e-04]\n",
      " [1.12230428e-01 8.87765755e-01 3.81696029e-06]\n",
      " [1.09813395e-01 8.90181659e-01 4.94600055e-06]\n",
      " [1.38954553e-01 8.60765862e-01 2.79584957e-04]\n",
      " [8.78610471e-01 9.39137506e-07 1.21388590e-01]\n",
      " [1.97398355e-01 8.02516405e-01 8.52398620e-05]\n",
      " [7.13930077e-01 9.21918560e-07 2.86069001e-01]\n",
      " [9.39973431e-01 1.12196495e-06 6.00254468e-02]\n",
      " [9.82411053e-02 9.01754818e-01 4.07650109e-06]\n",
      " [8.19566736e-01 1.28916580e-06 1.80431975e-01]\n",
      " [1.44014991e-01 8.55729298e-01 2.55711318e-04]\n",
      " [8.80417915e-01 9.44460782e-07 1.19581140e-01]\n",
      " [9.41853647e-01 9.94533728e-07 5.81453589e-02]\n",
      " [8.33690789e-01 9.08586425e-07 1.66308302e-01]\n",
      " [9.27675130e-01 1.53050235e-06 7.23233398e-02]\n",
      " [1.78699004e-01 8.21221177e-01 7.98195971e-05]\n",
      " [6.74847028e-01 2.73547067e-01 5.16059056e-02]\n",
      " [1.78134601e-01 8.21348144e-01 5.17254657e-04]\n",
      " [5.70503381e-01 1.52313289e-07 4.29496467e-01]\n",
      " [1.97887585e-01 8.01895642e-01 2.16773125e-04]\n",
      " [6.30838770e-01 2.28235912e-01 1.40925318e-01]\n",
      " [1.53222409e-01 8.46321401e-01 4.56190210e-04]\n",
      " [1.66011335e-01 8.33894739e-01 9.39263701e-05]\n",
      " [1.53222409e-01 8.46321401e-01 4.56190210e-04]\n",
      " [8.58323585e-01 8.79388129e-07 1.41675535e-01]\n",
      " [1.69347865e-01 8.30537550e-01 1.14585354e-04]\n",
      " [1.70032628e-01 8.29417882e-01 5.49490842e-04]\n",
      " [5.02593300e-01 1.32751517e-07 4.97406568e-01]\n",
      " [9.27675130e-01 1.53050235e-06 7.23233398e-02]\n",
      " [1.70032628e-01 8.29417882e-01 5.49490842e-04]\n",
      " [7.13930077e-01 9.21918560e-07 2.86069001e-01]\n",
      " [2.01763442e-01 7.97813318e-01 4.23240013e-04]\n",
      " [1.38258231e-01 8.61654836e-01 8.69333922e-05]\n",
      " [6.67380216e-03 1.47797139e-04 9.93178401e-01]\n",
      " [5.02593300e-01 1.32751517e-07 4.97406568e-01]\n",
      " [5.02593300e-01 1.32751517e-07 4.97406568e-01]\n",
      " [8.62472282e-02 9.13751964e-01 8.08209489e-07]\n",
      " [1.70032628e-01 8.29417882e-01 5.49490842e-04]\n",
      " [9.22597447e-01 1.19780893e-06 7.74013549e-02]\n",
      " [1.69347865e-01 8.30537550e-01 1.14585354e-04]\n",
      " [8.58323585e-01 8.79388129e-07 1.41675535e-01]\n",
      " [1.82785218e-01 8.16961230e-01 2.53551911e-04]\n",
      " [1.08858891e-01 8.91140117e-01 9.91914227e-07]\n",
      " [1.97398355e-01 8.02516405e-01 8.52398620e-05]\n",
      " [7.97752192e-01 7.60930255e-07 2.02247047e-01]]\n"
     ]
    }
   ],
   "source": [
    "states, obs = generate_HMM_sequences(trans_mat, obs_mat, stat_dist, length, num_samples) # generate sample sequences\n",
    "\n",
    "pos = np.random.randint(length, size = num_samples)\n",
    "\n",
    "print(\"transition matrix\")\n",
    "print(trans_mat)\n",
    "print(\"observation matrix\")\n",
    "print(obs_mat)\n",
    "print(\"stationary distribution\")\n",
    "print(stat_dist)\n",
    "print(\"states and observations, first half of each row is states\")\n",
    "print(np.concatenate((states, obs), axis = 1))\n",
    "print(\"positions: \", pos)\n",
    "h, x, hh = x_i_conditional_prob(trans_mat, obs_mat, stat_dist, obs, pos)\n",
    "print(\"Pr[H_i|x_-i], j-th row is for j-th sample and i=positions[j]:\")\n",
    "print(h)\n",
    "print(\"Pr[X_i|x_-i], j-th row is for j-th sample and i=positions[j]:\")\n",
    "print(x)\n",
    "print(\"Pr[H_i|x_i,x_-i], j-th row is for j-th sample and i=positions[j]:\")\n",
    "print(hh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "logh = np.log(h)\n",
    "x_one_hot = np.zeros((num_samples, num_obs))\n",
    "for i in range(num_samples):\n",
    "    x_one_hot[i, int(obs[i, pos[i]])] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = data.TensorDataset(torch.FloatTensor(features1), torch.FloatTensor(features2), torch.FloatTensor(labels))\n",
    "test_dl = data.DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1940, 0.8005, 0.0055],\n",
      "        [0.9354, 0.0079, 0.0567],\n",
      "        [0.9151, 0.0096, 0.0753],\n",
      "        [0.1632, 0.8344, 0.0024],\n",
      "        [0.9176, 0.0122, 0.0702],\n",
      "        [0.7959, 0.0061, 0.1980],\n",
      "        [0.8546, 0.0070, 0.1384],\n",
      "        [0.9354, 0.0079, 0.0567],\n",
      "        [0.1492, 0.8392, 0.0115]], grad_fn=<SliceBackward>)\n",
      "tensor([[1.9789e-01, 8.0190e-01, 2.1677e-04],\n",
      "        [9.4185e-01, 9.9453e-07, 5.8145e-02],\n",
      "        [9.2260e-01, 1.1978e-06, 7.7401e-02],\n",
      "        [1.6609e-01, 8.3381e-01, 9.4405e-05],\n",
      "        [9.2768e-01, 1.5305e-06, 7.2323e-02],\n",
      "        [7.9775e-01, 7.6093e-07, 2.0225e-01],\n",
      "        [8.5832e-01, 8.7939e-07, 1.4168e-01],\n",
      "        [9.4185e-01, 9.9453e-07, 5.8145e-02],\n",
      "        [1.5322e-01, 8.4632e-01, 4.5619e-04]])\n"
     ]
    }
   ],
   "source": [
    "for X1, X2, y in test_dl:\n",
    "    print(net(X1, X2)[:9])\n",
    "    print(y[:9])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
